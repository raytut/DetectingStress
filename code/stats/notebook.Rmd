---
title: "Momentary mood and arousal detect real-life prolonged stress"
author: "Rayyan Tutunji"
date: "21-04-2021"
output:
  html_notebook:
    number_sections: yes
    theme: flatly
    toc: yes
    toc_float: 
        collapsed: true 
  html_document:
    fig_height: 6
    fig_width: 9
    number_sections: yes
    theme: flatly
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: no
editor_options:
  chunk_output_type: inline
---


# Introduction

This analysis notebook accompanies the paper **Using wearable biosensors and ecological momentary assessments for the detection of prolonged stress in real life** by Tutunji et al. 2021, and utilizes data from the study "Stress Reslience and the Brain in Medical Students (STRAIN-MD)". Study design details can be founed in the [original article](paste link after publication), but a brief summary is provided here to assist in reading comprehension. In this study, participants completed two weeks of Ecological Momentary Asessments (EMA/ESM) coupled with Ecological Physiological Assessments (EPA). One of these weeks culminated in a high-stakes exam, while the other was outside of examination periods thus providing a stress and control week respectively. EMA consisted of questions regarding subjective stress, and positive and negative affect. EPA within the context of this study consisted of a [wearable device](https://www.empatica.com/research/e4/) that collected continuous measures of physiological arousal. Using these measures, we first validate our stress exposure by examining changes in subjective stress ratings between the two week. We then demonstrate the impact of stress exposure on mood and arousal measures. We then explore our findings by looking at continuous associations between subjective stress and outcomes. Finally, we demonstrate the feasibility of Mood and EPA measures in prediction of stress and control weeks using machine learning models. 

All custom functions and code can be found in [associated GitHub directory](https://github.com/raytut/DetectingStress/tree/main/code). Libraries used listed at the end of the document. In addition to the libraries, we also used prespecified themes for ggplots that make some plots easier to draw. These are all run in the set-up chunks. 

```{r Import Libraries, echo=FALSE, message=FALSE, warning=FALSE, setup=TRUE}

# Libraries to import and clean data
library(readxl)
library (tidyverse)
library(plyr)
library(broom)
library (hablar)
library(janitor)
library(data.table)
library(zoo)
library(scales) # Rescaling made easy

# Library for EMA
library (remotes)
#remotes::install_github("wviechtb/esmpack") # commented, needs to be installed from github
library(esmpack)
library(boot) 

# Basic Stats
library (psych)
library (psycho)
library(Hmisc)
library(RcmdrMisc)
library(corrr)
library(ppcor)

# Mixed Model 
library (lmerTest)
library(optimx) # Optimizer for lm 
library(olsrr) # Diagnostic for lmer
library(jtools) # Uses summ function for readable models that look pretty
library(sjPlot) # more modeling display
library(effectsize) # Get effect sizes from tstat
library(r2glmm) # Compute effect size directly
library(gamm4) # Alternative model fitting
library(performance)
    
# Parallel processing
library(future)
library(doSNOW)
library(randomForest)

#Plotting
library(ggplot2) # Standard plotting
library(qgraph) # MLVAR Network Plotting
library(ggpubr)
library(knitr)

#PCA
library(factoextra)

#Fonts and Pretty things
library(stargazer)
library(extrafont)

#font_import()
loadfonts(device="pdf")
```

In addition to the libraries, we also used prespecified themes for ggplots that make some plots easier to draw.
```{r}
# Theme 1
ggtheme <- theme (text=element_text(size=16,  family="Cambria"),
                  legend.position = "none",
                  axis.text.y = element_blank(),axis.text.x = element_text(size=16),
                  axis.ticks.y = element_blank(),
                  plot.title = element_text(size=16, hjust=0.5),
                  panel.background = element_rect(fill="transparent"),
                  panel.grid.minor.y = element_line(size=3),
                  panel.grid.major = element_line(colour = "aliceblue") )
# Theme 2
ptheme <- theme(text=element_text(size=11,  family="Calibri"), 
          axis.line = element_line(size = 1, colour = "grey"),
          panel.background = element_rect(fill="transparent"),
    plot.background = element_rect(fill = "transparent", color = NA), # bg of the plot
        panel.grid.minor.y = element_line(colour="grey95"),
        panel.grid.major.y = element_line(colour = "grey95")) 
  
# Set number of cores
NoCores <- as.numeric(availableCores())-1
  
```

Before starting, we also load the custom functions generated.
```{r}
source("functions.R")
```

# Data

We first load in the descriptive file here, and perfrom some cleaning to make the file more human friendly. The descriptive information is stored in a different file than the EMA information to avoid linking the any potential identifying information to the actual data. This section is redacted from the public documentation for this reason.

```{r}
# Get descritpive stats
EMA_descr <- read.delim("../data/descriptives.txt")

# Cleanup
EMA_descr$castor_record_id <- EMA_descr$Subject_ID
EMA_descr$Sex[EMA_descr$Contraceptive_use=="Male"] <- "Male"
EMA_descr$Sex[EMA_descr$Contraceptive_use!="Male"] <- "Female"
# Recode weeks and first scan as factor
EMA_descr$First_Week[EMA_descr$Column1 > 0] <- "Exam-First"
EMA_descr$First_Week[EMA_descr$Column1 < 0] <- "Control-First"

# Recode first scan
EMA_descr$First_Scan_Num <- EMA_descr$First_Scan
EMA_descr$First_Scan[EMA_descr$First_Scan_Num < 0] <- "Stress-First"
EMA_descr$First_Scan[EMA_descr$First_Scan_Num > 0] <- "Control-First"

```

Using python, we derived physiological features in 10-minute time windows prior to each EMA survey from the raw EPA data for each participant. Preprocessing is done through python with the [pyphysio package](https://github.com/MPBA/pyphysio) which has some tools for processing biosignals. EMA data is not processed during this phase and the raw output from the surveys is loaded into R. Among other things, the EMA and EPA signals contain the following features:

- Event Related Stress
- Activity Related Stress
- Physical Stress
- Social Stress
- Mood (Positive and Negative)
- Heart rate (High/Low Frequencey, RMSSD, IBI...)
- Skin Conductance (Phasic, Tonic, Magnitude...)
- Skin Temperature (Slope, Mean)
- Accelorometer Data (delta ACC, mean X,Y,Z direction)


We then load this file, and recode some variables and perfrom some specific cleaning steps. 
```{r EMA Data Import}

# Read Data
EMA_Data <- read.csv("../data/EMA_Clean_Features_10min.csv") 

# Precleaning
#First change types incase of improper input
EMA_Data %>% retype

# Some precleaning for variable generations
EMA_Data$obs <- as.numeric(EMA_Data$survey_package_name)
EMA_Data <- separate(EMA_Data, 'survey_package_name', c('ema_day','ema_beep'), sep = -1, remove=F)
EMA_Data$ema_beep_f <- as.factor(EMA_Data$ema_beep)
EMA_Data$ema_beep <- as.numeric(EMA_Data$ema_beep)
EMA_Data$ema_day <- as.factor(EMA_Data$ema_day)
EMA_Data$ema_day_num <- as.numeric(EMA_Data$ema_day)
EMA_Data$Sub_nr_week <-  with(EMA_Data, interaction(castor_record_id, week_type))
EMA_Data$ema_survey <- as.numeric(EMA_Data$survey_package_name)

# Merge with descriptive and remove dropouts from both dataframes
EMA_Data <- merge(EMA_Data, EMA_descr, by='castor_record_id')
EMA_Data <- filter(EMA_Data, EMA_Data$Wave != 0)
EMA_descr <- filter(EMA_descr, EMA_descr$Wave != 0)
EMA_Data$First_Week <- as.factor(EMA_Data$First_Week)
# Keep only distict
EMA_Data <- EMA_Data %>% distinct(Sub_nr_week, obs, .keep_all=T)

EMA_Data$week_type <- EMA_Data$week_type
EMA_Data$Week_Type <- factor(EMA_Data$week_type, levels=c('1','2'),
                         labels=c('Control','Stress'))
```


## Scoring variables

Before analyzing the data, still need to do some processing to standardize the variables to fit them to mixed models. As such, we process the questionnaire data and the EPA data below.

### EMA Variables {.tabset}

For each of the EMA scales, we transform some of the items, rescaled them, and then sum them. This varries for each catrogory of quesitons. 

#### Positive Affect {-}
Positive affect is on of our outcome measures. For positive affect (PA), we first rescale the variables from -3 to 3 into 1-7. The sums of the score is overall reported PA. 
```{r echo=TRUE}

## Positive: Rescale from -3-3 to 1 -7
EMA_Data$ema_happy <- (EMA_Data$ema_happy+4)
EMA_Data$ema_relax <- (EMA_Data$ema_relax+4)
EMA_Data$ema_cheer <- (EMA_Data$ema_cheer+4)
EMA_Data$ema_satisfied <- (EMA_Data$ema_satisfied+4)
#Total
EMA_Data$mood_positive <- rowSums(EMA_Data[,c("ema_happy","ema_relax","ema_cheer", "ema_satisfied")])

```

#### Negative Affect {-}
Simialr to PA, we do the same here for negative affect. We rescale the individual items, sum for total.
```{r echo=TRUE}
## Negative: Rescale
EMA_Data$ema_down <- (EMA_Data$ema_down+4)
EMA_Data$ema_guilty <-(EMA_Data$ema_guilty+4)
EMA_Data$ema_insecure <- (EMA_Data$ema_insecure+4)
EMA_Data$ema_lonely <- (EMA_Data$ema_lonely+4)
EMA_Data$ema_anxious <- (EMA_Data$ema_anxious+4)
# Total: Sum of measures
EMA_Data$mood_negative <- rowSums(EMA_Data[,c("ema_down","ema_guilty","ema_insecure","ema_lonely","ema_anxious")])

```

#### Event Stress {-}

Event related stress questions relate to most prominent event since last beep. For the items ranking the pleasantness, controlability, and expectedness, we need to reverse the score so that less positive events contribute more to the total. It is also scaled -3 to 3, with higher score being better.I will reverse scale the items. So if an event is more pleasant, the event stress score goes down for example. Event importance is just rescaled to 1-7.
```{r echo=TRUE}
# Reverse scale the pleasantness
 EMA_Data$event_pleasant <- (EMA_Data$event_pleasant+4)
EMA_Data$event_pleasant <- (8-EMA_Data$event_pleasant)
EMA_Data$event_pleasant <- (EMA_Data$event_pleasant-4)
# Importance rescaled 1-7
EMA_Data$event_importance <- (EMA_Data$event_importance+4)
# Reverse score Controlability
EMA_Data$event_control <- (EMA_Data$event_control+4)
EMA_Data$event_control <- (8-EMA_Data$event_control)
EMA_Data$event_control <- (EMA_Data$event_control-4)
# Reverse score Expectedness
EMA_Data$event_expect<-(EMA_Data$event_expect+4)
EMA_Data$event_expect<-(8-EMA_Data$event_expect)
EMA_Data$event_expect<-(EMA_Data$event_expect-4)
# Sum for Total
EMA_Data$event_tot <- rowSums(EMA_Data[,c ("event_pleasant","event_importance","event_control","event_expect")])

```

#### Activtiy Stress {-}
Activity related stress retains to the activity participants are currently doing right before the beep. The skilled and preference measure are also reversed. More skilled=Lower score. Same with preference. 
```{r echo=TRUE}
# Rever Skillfullness
EMA_Data$activity_skill<-(EMA_Data$activity_skill+4)
EMA_Data$activity_skill<-(8-EMA_Data$activity_skill)
EMA_Data$activity_skill<-(EMA_Data$activity_skill-4) 
# Rescaled preference 1-7
EMA_Data$activity_preference<-(EMA_Data$activity_preference+4)
# Rescaled preference 1-7
EMA_Data$activity_effort<-(EMA_Data$activity_effort+4)
# Sum for total
EMA_Data$activity_tot<-rowSums(EMA_Data[,c("activity_skill", "activity_preference", "activity_effort")])
```

#### Social Stress {-}

Social stress items relate to the social situation participants are in. There are two branches: Either you are alone, or you are with someone. Both these branches will contribute to the total score. Some measures are reveresed, and some are just brought into the positive. We again get the sum score, ignoring the NaNs since questions are dependant on branch.
```{r echo=TRUE}
# Rescale if they want to be alone or with someone 1-7
EMA_Data$social_alone<-(EMA_Data$social_alone +4)
EMA_Data$social_with <- (EMA_Data$social_with+4)
# Reverse the pleasantness scale
EMA_Data$social_pleasant <- (EMA_Data$social_pleasant + 4)
EMA_Data$social_pleasant <- (8-EMA_Data$social_pleasant)
# Reverse the at ease scale
EMA_Data$social_ease<- (EMA_Data$social_ease + 4)
EMA_Data$social_ease<- (8-EMA_Data$social_ease)
# Reverse the self scale
EMA_Data$social_self<- (EMA_Data$social_self + 4)
EMA_Data$social_self<- (8-EMA_Data$social_self)
# Reverse the at ease alone scale
EMA_Data$social_alone_ease<-(EMA_Data$social_alone_ease +4)
EMA_Data$social_alone_ease<- (8-EMA_Data$social_alone_ease)
#Total. Make sure that nans are not dropped because in the event they are alone, the social items are different
EMA_Data$social_tot<-rowSums(EMA_Data[,c ("social_alone","social_with","social_pleasant","social_ease", "social_self", "social_alone_ease")], na.rm=TRUE)

```

#### Physical Stress {-}

Items relate to physical experiences of discomfort. These are control items. We do similar steps as before. We bring to scores from (-3 > 3) to (1 > 7) scaling, and get a sum score. We then just get the sum score for this. In this section we also rescale the excercise items which we use as covariates later
```{r echo=TRUE}
#First recode
EMA_Data$physical_tired<-(4+EMA_Data$physical_tired)
EMA_Data$physical_well<-(4+EMA_Data$physical_well)
EMA_Data$physical_pain<- (4+EMA_Data$physical_pain)
EMA_Data$physical_hunger<- (4+EMA_Data$physical_hunger)
EMA_Data$physical_temp<- (4+EMA_Data$physical_temp)
#Total
EMA_Data$physical_tot<-rowSums(EMA_Data[,c("physical_tired","physical_well","physical_pain", "physical_hunger","physical_temp")])

# Also while Im here I do the excercise Items
EMA_Data$event_duration[is.na(EMA_Data$event_duration)] <- 0
EMA_Data$physical_excercise_dur <-((EMA_Data$event_duration))/max(EMA_Data$event_duration)
```

#### Center, scale, and lag {-}

Next we center the variables, rescale them, and also lag them (temporal lagging -1). This is done as a loop for each of the summed items. 
```{r}
# Variables to rescale
rescale_ema <- c("mood_positive", "mood_negative", "event_tot", "activity_tot", "social_tot", "physical_tot", "physical_excercise_dur")

# Rescaling
for (i in rescale_ema){
    #Subject Mean centering
    cen <- paste(i, "c", sep="_")
    EMA_Data[cen] <- calc.mcent(x=EMA_Data[[i]], id=castor_record_id, data=EMA_Data)
    # Z-Transform
    ztrans <- paste(i, "z", sep="_")
    EMA_Data[ztrans] <- scale(EMA_Data[[i]], center = TRUE, scale = TRUE)
    # Rescale
    stran <- paste(i, "s", sep="_")
    EMA_Data[stran] <- scales::rescale(EMA_Data[[ztrans]], to=c(1, 10))
    # Get Mean
    smean <- paste(i, "m", sep="_")
    EMA_Data[smean] <- calc.mean(EMA_Data[[i]], id=Sub_nr_week, data=EMA_Data, expand=TRUE)
    # Z-Transom mean 
    mztrans <- paste(i, "mz", sep="_")
    EMA_Data[mztrans] <- scale(EMA_Data[[smean]], center = TRUE, scale = TRUE)
    # Lag the variable
    lagtrans <- paste(i, "l", sep="_")
    EMA_Data[lagtrans] <- lag_var(x=stran, id="Sub_nr_week", obs="obs", day= "ema_day_num", data=EMA_Data, lag=1)   
}

# I cant do this in a loop, but I also want to rescale the subject centered values
EMA_Data <-EMA_Data %>% group_by(castor_record_id) %>%
    mutate(mood_positive_cs= scales::rescale(mood_positive_c,to=c(1,10)),
           mood_negative_cs= scales::rescale(mood_negative_c,to=c(1,10)),
           event_tot_cs= scales::rescale(event_tot_c,to=c(1,10)),
           activity_tot_cs= scales::rescale(activity_tot_c,to=c(1,10)),
           social_tot_cs= scales::rescale(social_tot_c,to=c(1,10)),
           physical_tot_cs= scales::rescale(physical_tot_c,to=c(1,10))) %>% ungroup()
```


#### Mean Stress {-}
After deriving the rescaled measures, we also calculate the mean stress states which we use for plotting our variables.
```{r}
##Average stress Measure
EMA_Data$mean_stress <- rowSums(EMA_Data[c('event_tot_z', 'activity_tot_z', 'social_tot_z')], na.rm=TRUE)
EMA_Data$mean_stress_c <- rowSums(EMA_Data[c('event_tot_c', 'activity_tot_c', 'social_tot_c')], na.rm=TRUE)
EMA_Data$mean_stress_s <- scales::rescale(EMA_Data$mean_stress_c, to=c(1, 10))
EMA_Data$mean_stress_l <- lag_var(x="mean_stress_c", id="Sub_nr_week", obs="obs", day= "ema_day_num", data=EMA_Data, lag=1)

```

### EPA Variables {.tabset}

Now we can clean up some of the physiology data. Since most of the cleaning has already been done in python, only more basic processing is done here. For example, there was one watch that had a faulty temperature sensor. To avoid losing data for a variable in our covariates only, we replace this with values from the mean and standard deviation of the population instead. 

```{r echo=TRUE}
# Count of replaced entries
n_temp <- count(EMA_Data$temp_mean > 50)
n_replace <- n_temp$freq[2]
# Subset dataframe with normal values
temp_df <- EMA_Data
temp_df <- filter(temp_df, temp_df$temp_mean < 50)
# Convert mean nans to 0 to apply condition replacement
EMA_Data$temp_mean[is.na(EMA_Data$temp_mean)] <- 0

# Loop over temperature values for replacement
temp_variables <- list("temp_median", "temp_sd", "temp_slope", "temp_mean")
for (i in temp_variables){
    # Get the mean and SD to replace values 
    mean_t <- mean((temp_df[[i]]), na.rm=T)
    sd_t<- sd((temp_df[[i]]),na.rm=T)
    # Replace Mean Temp with distribution
    temp_vect <- runif(n=n_replace, min = (mean_t-sd_t), max =(mean_t+sd_t)) # Vector for replacements
    EMA_Data[i] <- replace(EMA_Data[[i]], (EMA_Data$temp_mean>50), temp_vect)
}

# Revert 0 to NAN
EMA_Data$temp_mean[EMA_Data$temp_mean==0] <- NA

```


Second, in the python script, if no skin coductance responses are detected, our pipeline returns NaNs. This is not an adequate representation of the data, and as such, we replace periods where signal was detected, but no responses were detected with 0. 

```{r}
EMA_Data$sc_phasic_dur[(!is.na(EMA_Data$sc_tonic_mean)) & (is.na(EMA_Data$sc_phasic_dur))] <- 0
EMA_Data$sc_phasic_num[(!is.na(EMA_Data$sc_tonic_mean)) & (is.na(EMA_Data$sc_phasic_num))] <- 0
EMA_Data$sc_phasic_mag[(!is.na(EMA_Data$sc_tonic_mean)) & (is.na(EMA_Data$sc_phasic_mag))] <- 0

``` 

We will finally subject center, rescale, and mean center the EPA data simalr to the EMA data. We do this for each of our measures below.

#### Heart Rate {-}
```{r}
# Variables to rescale
rescale_phy <- c("hr_mean", "hr_sd", "hr_min", "hr_max", "ibi_mean", "ibi_sd")

# Rescaling
for (i in rescale_phy){
    #Subject Mean centering
    cen <- paste(i, "c", sep="_")
    EMA_Data[cen] <- calc.mcent(x=EMA_Data[[i]], id=castor_record_id, data=EMA_Data)
    # Z-Transform
    ztrans <- paste(i, "z", sep="_")
    EMA_Data[ztrans] <- scale(EMA_Data[[i]], center = TRUE, scale = TRUE)
    # Rescale
    stran <- paste(i, "s", sep="_")
    EMA_Data[stran] <- scales::rescale(EMA_Data[[ztrans]], to=c(1, 10))
    # Get Mean
    smean <- paste(i, "m", sep="_")
    EMA_Data[smean] <- calc.mean(EMA_Data[[i]], id=Sub_nr_week, data=EMA_Data, expand=TRUE)
    # Z-Transom mean 
    mztrans <- paste(i, "mz", sep="_")
    EMA_Data[mztrans] <- scale(EMA_Data[[smean]], center = TRUE, scale = TRUE)
    # Lag the variable
    lagtrans <- paste(i, "l", sep="_")
    EMA_Data[lagtrans] <- lag_var(x=stran, id="Sub_nr_week", obs="obs", day= "ema_day_num", data=EMA_Data, lag=1)   
}


# Now to get cs values
EMA_Data <-EMA_Data %>% group_by(castor_record_id) %>%
    mutate(hr_mean_cs= scales::rescale(hr_mean_c,to=c(1,10)),
           hr_min_cs= scales::rescale(hr_min_c,to=c(1,10)),
           hr_max_cs= scales::rescale(hr_max_c,to=c(1,10))) %>% ungroup()

```

#### Skin Conductance {-}
```{r}

# Variables to rescale
rescale_phy <- c("sc_tonic_mean", "sc_phasic_mean", "sc_phasic_mag" , "sc_phasic_dur", "sc_phasic_num", "sc_phasic_auc")

# Rescaling
for (i in rescale_phy){
    #Subject Mean centering
    cen <- paste(i, "c", sep="_")
    EMA_Data[cen] <- calc.mcent(x=EMA_Data[[i]], id=castor_record_id, data=EMA_Data)
    # Z-Transform
    ztrans <- paste(i, "z", sep="_")
    EMA_Data[ztrans] <- scale(EMA_Data[[i]], center = TRUE, scale = TRUE)
    # Rescale
    stran <- paste(i, "s", sep="_")
    EMA_Data[stran] <- scales::rescale(EMA_Data[[ztrans]], to=c(1, 10))
    # Get Mean
    smean <- paste(i, "m", sep="_")
    EMA_Data[smean] <- calc.mean(EMA_Data[[i]], id=Sub_nr_week, data=EMA_Data, expand=TRUE)
    # Z-Transom mean 
    mztrans <- paste(i, "mz", sep="_")
    EMA_Data[mztrans] <- scale(EMA_Data[[smean]], center = TRUE, scale = TRUE)
    # Lag the variable
    lagtrans <- paste(i, "l", sep="_")
    EMA_Data[lagtrans] <- lag_var(x=stran, id="Sub_nr_week", obs="obs", day= "ema_day_num", data=EMA_Data, lag=1)   
}

# Now to get cs values
EMA_Data <-EMA_Data %>% group_by(castor_record_id) %>%
    mutate(sc_tonic_mean_cs= scales::rescale(sc_tonic_mean_c,to=c(1,10)),
           sc_phasic_mag_cs= scales::rescale(sc_phasic_mag_c,to=c(1,10)),
           sc_phasic_dur_cs= scales::rescale(sc_phasic_dur_c,to=c(1,10)),
            sc_phasic_auc_cs= scales::rescale(sc_phasic_auc_c,to=c(1,10)),
            sc_phasic_num_cs= scales::rescale(sc_phasic_num_c,to=c(1,10))) %>% ungroup()
```

#### Temperature {-}
```{r}

# Temp
# Mean
EMA_Data$temp_mean_c <- calc.mcent(temp_mean,Sub_nr_week, data=EMA_Data )
EMA_Data$temp_mean_z <- scale(EMA_Data$temp_mean, center = TRUE, scale = TRUE)
EMA_Data$temp_mean_l <- lag_var(x="temp_mean_z", id="Sub_nr_week", obs="obs", day= "ema_day_num", data=EMA_Data, lag=1)
# Slope
EMA_Data$temp_slope_c <- calc.mcent(temp_slope,Sub_nr_week, data=EMA_Data )
EMA_Data$temp_slope_z <- scale(EMA_Data$temp_slope, center = TRUE, scale = TRUE)
EMA_Data$temp_slope_l <- lag_var(x="temp_slope_z", id="Sub_nr_week", obs="obs", day= "ema_day_num", data=EMA_Data, lag=1)
# SD
EMA_Data$temp_sd_c <- calc.mcent(temp_sd,Sub_nr_week, data=EMA_Data )
EMA_Data$temp_sd_z <- scale(EMA_Data$temp_sd, center = TRUE, scale = TRUE)
```


# Descriptives Stats

Before running any stats, we should take a look at some descriptive stats to get an overall feel of our data. We do this in two parts, looking at the population descriptives, and then the physiology descriptives.

## Compliance Rates  {.tabset}

Lets first check compliance rates to see how well our subjects adhered to the sampling scheme. We first check the compliance rates uncorrected for the time at which they were acquired, followed by correction of the time limits. We set this to 1 hour since we only have 6 surveys, and our subjects had varying time schedules. 

### Uncorrected Compliance {-}
Compliance rates uncorrected for time off-sets
```{r EMA Data: Check compliance}
# Recod compliance variable
EMA_Data$completed[EMA_Data$survey_progress==100] <- 1 
# Per subject
calc.nomiss(completed, castor_record_id, data=EMA_Data, prop=T)
# more summary statistics for compliance
summary(calc.nomiss(completed, castor_record_id, data=EMA_Data, prop=TRUE))
```

Without correcting for time offsets, our EMA measures seem to be nice. Lets see if I correct for timing if it makes a difference next what will happen. We will give participant one hour to finish the survey. If they don't finish it in that time window, we will count it as missing.

### Corrected Compliance {-}
Compliance rates correcting for time of completion. First drop any survey that is not complete more than 80%. I then create a variable that tells as when the survey was completed in terms of time (not date). I then conditionally set the completion variable to zero if the survey does not fall within the completed time window given the beep. 
```{r EMA Data: Check Compliance while account for Time}

# Set up some stuff for replace and refill
EMA_Data$survey_completed_on <- as.character(EMA_Data$survey_completed_on)
EMA_Data$survey_completed_time <- as.ITime(EMA_Data$survey_completed_on)
EMA_Data$completed[EMA_Data$survey_progress < 80] <- 0 

# Replace and refill conditionals for completion, factoring times
EMA_Data$completed[EMA_Data$survey_completed_time >= (as.ITime("10:30:00")) & EMA_Data$ema_beep==1] <- 0
EMA_Data$completed[EMA_Data$survey_completed_time >= (as.ITime("13:00:00")) & EMA_Data$ema_beep==2] <- 0
EMA_Data$completed[EMA_Data$survey_completed_time >= (as.ITime("15:30:00")) & EMA_Data$ema_beep==3] <- 0
EMA_Data$completed[EMA_Data$survey_completed_time >= (as.ITime("18:00:00")) & EMA_Data$ema_beep==4] <- 0
EMA_Data$completed[EMA_Data$survey_completed_time >= (as.ITime("20:30:00")) & EMA_Data$ema_beep==5] <- 0
EMA_Data$completed[EMA_Data$survey_completed_time >= (as.ITime("23:00:00")) & EMA_Data$ema_beep==6] <- 0

# Reformat 0 to Nan, and get new completion rates
EMA_Data$completed[EMA_Data$completed == 0] <- NA
calc.nomiss(completed, castor_record_id, data=EMA_Data,prop=TRUE)
summary(calc.nomiss(completed, castor_record_id, data=EMA_Data,prop=TRUE))
```

### Usable Physiology {-}
We also check the completion rates for periods where we have detected usable physiology in our pipeline. We do this by estimating the number of times where we successfully detected skin conductance,
```{r}
summary(calc.nomiss(sc_tonic_mean, castor_record_id, data=EMA_Data,prop=TRUE))
```

When we correct for the timing, we actually still have decent completion rates. Finally we filter out all incomplete surveys and those outside our time windows for our overall analysis. 
```{r}
EMA_Data <- EMA_Data %>% dplyr::filter(!is.na(completed)) 
```


## Populations Descriptives {.tabset}

We next take a look at population descriptive that we would like to report.

### Sex {-}
```{r}
describe(EMA_descr$Sex)
```
### Contraceptive Use {-}
This is interesting for other analyses we want to do with other data
```{r}
describe(factor(EMA_descr$Contraceptive_use))
```
### Program {-}
```{r}
describe((EMA_descr$Program))
```
### First Week {-}
```{r}
describe(EMA_descr$First_Week)
```
### Days Between Weeks {-}
```{r}
# Number of days between weeks
summary(abs(EMA_descr$Column1))
```

### Survey Disruption {-}
Asking whether the surveys disrupted the participants.
```{r}
psych::describe(EMA_Data$physical_disruption)
ggplot(EMA_Data, aes(x=physical_disruption)) + geom_histogram(bins = 7)
```


## Physiology Descriptive {.tabset}

After getting the population descriptive, we should next derive some E4 Quality measures. A lot of the data which is poor quality is already removed early on in the preprocessing pipeline. Instead we can check how many recordings were captured for the IBI data, and the overall movement during testing.

### IBI Based Quality {-}
This is a measure of what duration of time the detected heart beats cover. So within a 10minute time window, we would want to detect 10 minutes of total IBI time if we had 100% signal. We see that for the mean is 27% of time with beats detected instead. This indicates that we do not have enough data for temporal domain analysis. 
```{r}
ggplot(EMA_Data, aes(x=ibi_based_quality, colour=ibi_based_quality)) + geom_histogram()
count(EMA_Data$ibi_based_quality > 0.3)
psych::describe(EMA_Data$ibi_based_quality)
```

### IBI and ACC {-}
Next we will check if the IBI quality is related to the ACC data. This gives us a good idea of how much motion is affecting our data. We see it has a big impact. When people are not moving, we are able to detect the entire IBI window. This means we should include movement in our models. 
```{r}
ggplot(EMA_Data, aes(x=ibi_based_quality, y=acc_delta)) + geom_smooth(method="lm", fullrange=F ) + coord_cartesian(ylim = c(0,10), xlim=c(0, 2.5))  + ggtheme + theme(axis.ticks.y=element_line(size=1), axis.text.y = element_text(size=12)) + ylab("ACC Delta") + xlab ("IBI Based Quality")
```

### IBI Quality and HR SD {-}
Next, we check if the IBI Quality effects the SD of the HR measures. It looks like it does have an impact, meaning we likely cant use that measure. 
```{r}
ggplot(EMA_Data, aes(x=ibi_based_quality, y=hr_sd)) + geom_smooth(method="lm", fullrange=F ) + ggtheme + theme(axis.ticks.y=element_line(size=1), axis.text.y = element_text(size=12)) + ylab("HR SD") + xlab ("IBI Based Quality")

summary(lm(ibi_based_quality ~ hr_sd, data=EMA_Data))

```

### SC and ACC {-}
Next we will check if the skin conductance signals are related to the ACC. Basically this is just doing exploratory analysis to double check whether movement also impacts skin conductance measures. We see here that it also does indeed impact our measures. 
```{r message=FALSE, warning=FALSE}

fig.sc_tonic <- ggplot(EMA_Data, aes(x=sc_tonic_mean, y=acc_delta)) + geom_smooth(method="lm", fullrange=F )   + ggtheme + theme(axis.ticks.y=element_line(size=1), axis.text.y = element_text(size=12)) + ylab("ACC Delta") + xlab ("SC Tonic")  
fig.sc_mag <- ggplot(EMA_Data, aes(x=sc_phasic_mag, y=acc_delta)) + geom_smooth(method="lm", fullrange=F )   + ggtheme + theme(axis.ticks.y=element_line(size=1)) + xlab ("SC Mag") 

fig.sc_num <- ggplot(EMA_Data, aes(x=sc_phasic_num, y=acc_delta)) + geom_smooth(method="lm", fullrange=F )   + ggtheme + theme(axis.ticks.y=element_line(size=1)) + xlab ("SC Num") 

fig.sc_auc <- ggplot(EMA_Data, aes(x=sc_phasic_auc, y=acc_delta)) + geom_smooth(method="lm", fullrange=F )   + ggtheme + theme(axis.ticks.y=element_line(size=1)) +  xlab ("SC AUC") 

fig.sc_dur <- ggplot(EMA_Data, aes(x=sc_phasic_dur, y=acc_delta)) + geom_smooth(method="lm", fullrange=F )   + ggtheme + theme(axis.ticks.y=element_line(size=1)) + xlab ("SC Dur")  

fig.temp_mean <- ggplot(EMA_Data, aes(x=physical_excercise_dur, y=acc_delta, colour="red")) + geom_smooth(method="lm") + ggtheme 
ggarrange(fig.sc_tonic, fig.sc_mag, fig.sc_num, fig.sc_auc, fig.sc_dur, fig.temp_mean)

```

### SC Mag and number {-}
```{r message=FALSE, warning=FALSE}
fig.sc_mag <- ggplot(EMA_Data, aes(x=sc_phasic_mag, y=sc_phasic_num)) + geom_smooth(method="lm", fullrange=F )   + ggtheme + theme(axis.ticks.y=element_line(size=1)) + xlab ("SC Mag") 
fig.sc_mag
```

## Trends in EMA
We finally plot the graphs of the EMA items over time in each of the weeks for some exploratory analysis.We see here that there is an effect of time (higher stress in mid-day), and an effect of day. The closer they are to exams, the more stressed they are. This means we need to include these in our models. 
```{r message=FALSE, warning=FALSE}

vars.ema <- c( "event_tot_z", "activity_tot_z", "social_tot_z", "physical_tot_z", "mood_positive_z", "mood_negative_z")
for ( i in vars.ema) {
    p1 <- ggplot(EMA_Data, aes(y=get(i), x=ema_survey, colour=Week_Type, fill=Week_Type)) + geom_line(stat="summary") + geom_ribbon(stat="summary", alpha=0.3, color=NA) + scale_x_continuous() + ylab(i)
  print(p1)
}

```

.

## Aggregate Stress {.tabset}

After plotting our variables over all the week, it will be interesting to check the aggregate stress changes, and how each subjects stress reactivity looks like. For this, we make an average dataframe across the weeks, so we can look at the average change in mood. 

```{r Plot: Aggregate and Stress Change, warning=FALSE}
#Average Stress per Week:
EMA_avg <- EMA_Data
# Now I can do some merging
EMA_avg <- aggregate(EMA_avg, by=list(EMA_avg$castor_record_id, EMA_avg$Week_Type), FUN=mean, na.rm=T, na.warn=F)
EMA_avg$castor_record_id <- EMA_avg$Group.1
EMA_avg$Week_Type <- EMA_avg$Group.2
EMA_avg$Week_Type <- factor(EMA_avg$Week_Type, levels=c('Control','Stress'),
                     labels=c('Control','Exam'))

# Split the averaged DF to control and stress week
EMA_avg_exam <- subset(EMA_avg, Week_Type=="Exam") 
EMA_avg_control <- subset(EMA_avg, Week_Type!="Exam") 

# Merge by week to calculate change
EMA_avg_wide <-  merge(EMA_avg_exam, EMA_avg_control, by='castor_record_id', suffixes=c('_exam', '_control'))

# Make Aggregated variables 
EMA_avg_wide$mood_positive <-((EMA_avg_wide$mood_positive_control + EMA_avg_wide$mood_positive_exam)/2)
EMA_avg_wide$mood_negative <-((EMA_avg_wide$mood_negative_control + EMA_avg_wide$mood_negative_exam)/2)
EMA_avg_wide$activity_tot <-((EMA_avg_wide$activity_tot_control + EMA_avg_wide$activity_tot_exam)/2)
EMA_avg_wide$social_tot <-((EMA_avg_wide$social_tot_control + EMA_avg_wide$social_tot_exam)/2)
EMA_avg_wide$event_tot <-((EMA_avg_wide$event_tot_control + EMA_avg_wide$event_tot_exam)/2)
EMA_avg_wide$physical_tot <-((EMA_avg_wide$physical_tot_control + EMA_avg_wide$physical_tot_exam)/2)

# Make stress change, and mean centrer it
EMA_avg_wide$stress_reactivity <- EMA_avg_wide$mean_stress_exam - EMA_avg_wide$mean_stress_control
EMA_avg_wide$stress_reactivity_c <- EMA_avg_wide$mean_stress_c_exam - EMA_avg_wide$mean_stress_c_control
EMA_avg_wide$stress_reactivity_z <- scale(EMA_avg_wide$stress_reactivity, center = TRUE, scale = TRUE)

```


### Mean Change in Stress {-}
```{r}
#Box Plot
mean_box <- ggplot(EMA_avg, aes(y=mean_stress, x=Week_Type, colour=Week_Type,fill=Week_Type, na.rm = TRUE)) +
  geom_boxplot(alpha=1/2) + geom_jitter(width=0.1, alpha=1/2)+
  scale_y_continuous()+ scale_x_discrete()+
  ggtitle("Stress Levels per Week")+
  xlab("") + ylab("Aggregated stress measure\n")+ ggtheme
mean_box #+ coord_fixed(ratio=1)
```

### Stress Rectivity Heat Plot {-}
```{r}
scat_str <- ggplot (EMA_avg_wide, aes(y=stress_reactivity_c, x=0, colour=stress_reactivity_c) ) +
    geom_jitter( width = 0.7, alpha=0.75, size = 2) + scale_x_continuous()+
    ggtitle("Individual Stress Reactivity to Exams\n")+ylab("Stress\nReactivity\n")+labs(color = "Stress\nReactivity\n")+
    theme(text=element_text(size=18,  family="Cambria"),
        plot.title=element_text (size=20, hjust=0.5),
        axis.title.x=element_blank(),axis.text.x=element_blank(),axis.ticks.x=element_blank(),
        axis.text.y = element_text(size=18),axis.title.y=element_text(size=18),
        panel.background = element_rect(fill="white"),
        panel.grid.minor.y = element_line(size=3),
        panel.grid.major = element_line(colour = "aliceblue"))
scat_str + scale_color_gradient(low="blue", high="red") + coord_fixed(xlim = c(-5,5))
```
 
  

# Inferential Stats

We can now run the actual statistics. We use mixed effects models to first validate our paradigm by looking at overall changes in our subjective stress measures between the two weeks. We then go one to investigate the effects of the stress exposure (i.e., stress week) on our outcomes of affect and arousal. We finally investigate and explore the moment-to-moment associations between subjective stress and the outcomes, and then further explore these effects with follow-up analyses and a mediation analysis. 

All our models are fit in a maximal approach. We fit fixed effects for all the main effect of interest, with a random slope. We also fit fixed effects with fixed slopes for all the covariates. If a covariate is categorical with fewer than 6 levels, then we only fit fixed effects and no random slopes. Finally, we model subject as the main random effect. For each model, we test the multiple families and links, and using the AIC and residual fit, we select the best model. In the results below, we present the final selected models for brevity. Models are commented when producing this notebook to simplify the generation of the html file. 

Additionally, we check models for mulitcolinearity using models without interaction terms. Models reported here are the final ones, with the interaction terms which inflates multicolinearity estimates.


## Week vs Week Differences

The first set of analysis look at differences between the stress and control weeks. We model this as a fixed effect, and additionally model covariates as fixed effects for sex, study program, week order, day and time, movement, and exercise. We model fixed slopes for the covariates with multiple levels, and a random slope for the fixed effect of interest.

### Subjective Stress {.tabset }

The first models will look at the subjective stress measures, and how those change between the weeks. Based on these models, we can see that there is a significant overall effect of week type on most of our stress measures, which is great. Our stress induction is working. This means we have higher subjective stress in our stress week, indicating our design is achieving its goal. 


#### Event Related Stress {-}
Event related stress is related to the most prominent event participants expreinced in between the surveys.
```{r}
# Model
# glmer.event_week <- lmer(event_tot_s ~ Week_Type +  #Model week
#     Sex + Program +  # Model sex and program 
#     First_Week + ema_day*ema_beep_f + # Model day related items
#     acc_delta +  physical_excercise_dur + acc_delta*physical_excercise_dur + # Model movement
#     (1+Week_Type|castor_record_id) + (0+acc_delta|castor_record_id) + 
#     (0+ema_survey|castor_record_id) + (0+physical_excercise_dur|castor_record_id) + 
#     (1|castor_record_id:ema_day:ema_beep_f),
#     data=EMA_Data,
#     #family=gaussian,
#     control=lmerControl(calc.derivs = FALSE))

# Model Summary
model_output(glmer.event_week)

```



#### Activity Related Stress {-}
Activity related stress is stress related to the activity participants were engaged in just before receiving the survey.
```{r}
# Model
# glmer.activity_week <- lmer(activity_tot_s ~ Week_Type +  #Model week
#     Sex + Program +  # Model sex and program 
#     First_Week + ema_day*ema_beep_f + # Model day related items
#     acc_delta +  physical_excercise_dur + acc_delta*physical_excercise_dur + # Model movement
#     (1+Week_Type|castor_record_id) + (0+acc_delta|castor_record_id) + 
#     (0+ema_survey|castor_record_id) + (0+physical_excercise_dur|castor_record_id) + 
#     (1|castor_record_id:ema_day:ema_beep_f),
#     data=EMA_Data,
#     #family=gaussian,
#     control=lmerControl(calc.derivs = FALSE))

# Model Summary
model_output(glmer.activity_week )

```



#### Social Stress {-}
Relates to stress derived from social interactions, or lack thereof.
```{r}
# Model
# glmer.social_week <- glmer( social_tot_s ~ Week_Type +  #Model week
#     Sex + Program +  # Model sex and program 
#     First_Week + ema_day*ema_beep_f + # Model day related items
#     acc_delta +  physical_excercise_dur + acc_delta*physical_excercise_dur + # Model movement
#     (1+Week_Type|castor_record_id) + (0+acc_delta|castor_record_id) + 
#     (0+ema_survey|castor_record_id) + (0+physical_excercise_dur|castor_record_id) + 
#     (1|castor_record_id:ema_day:ema_beep_f),
#     data=EMA_Data,
#     family=Gamma(link="log"),
#     control=glmerControl(calc.derivs = FALSE, optCtrl=list(maxfun=100000)))

# Model Summary
model_output(glmer.social_week)

```


#### Physical Stress {-}
Control items assessing physical discomfort or illness. 
```{r warning=FALSE}
# Model
# glmer.physical_week<- lmer( physical_tot_s ~ Week_Type +  #Model week
#     Sex + Program +  # Model sex and program 
#     First_Week + ema_day*ema_beep_f + # Model day related items
#     acc_delta +  physical_excercise_dur + acc_delta*physical_excercise_dur + # Model movement
#     (1+Week_Type|castor_record_id) + (0+acc_delta|castor_record_id) + 
#     (0+ema_survey|castor_record_id) + (0+physical_excercise_dur|castor_record_id) + 
#     (1|castor_record_id:ema_day:ema_beep_f),
#     data=EMA_Data,
#     #family=Gamma,
#     control=lmerControl(calc.derivs = FALSE))

# Model Summary
model_output(glmer.physical_week)

```  

#### Results: Subjective Stress v Week{-}
We tabulate the results, and produce a regression effect plot to visualize the results. 
```{r}
table.stress_week <- tab_model(glmer.event_week, glmer.activity_week,  glmer.social_week, glmer.physical_week, 
           terms=c("(Intercept)","Week_Type [Stress]", "Sex [Male]", "Program [BSc_Med]", "First_Week [Exam-First]", "acc_delta", "physical_excercise_dur"), 
          dv.labels=c("Event", "Activitiy", "Social", "Physical"), 
          title="Table 1. Subjective Stress vs Week Type", show.df=F, show.fstat = T,
          transform=NULL, 
         show.stat=TRUE,
         show.se=TRUE)
htmlTable::htmlTable(table.stress_week$knitr)

```


```{r}
# Subset the variables we want to plot
plot.mood_week <- plot_models(glmer.event_week, glmer.activity_week, glmer.social_week, glmer.physical_week)
rm_term <- as.vector(plot.mood_week$data$term[1:length(plot.mood_week$data$term)])
rm_term <- rm_term[rm_term != "Week_TypeStress"]

# Make the plot
plot.mood_week <- plot_models(glmer.event_week, glmer.activity_week, glmer.social_week, glmer.physical_week,
                                  m.labels=c("Event Stress", "Activity Stress","Social Stress", "Physical Stress" ),
                                  axis.labels = c(" "),
                                # Stastistical Stuff
                                rm.terms = rm_term,
                                #show.values = T,
                                #value.size = 4, 
                                #std.est=T, 
                                show.p=T,
                                p.shape=T,
                                legend.pval.title = "Significance", 
                                # Visual Stuff
                                colors="#666666",
                                dot.size=2,
                                line.size = 1,
                                spacing=1 , 
                                vline.color = "darkgrey", 
                                legend.title = "") + ylab("\nParameter Estimate (a.u.)") + xlab("Subjective Stress") + 
                                ptheme + 
                                theme(axis.ticks.y=element_blank(), 
                                      legend.text=element_text(size=16), legend.title = element_text(size=16),
                                      axis.title = element_text(size=16),axis.text.x=element_text(size=11),
                                      panel.grid.major.x = element_line(colour = "grey95"),
                                      panel.grid.minor.x = element_line(colour = "grey90")) 

# Show and save
plot.mood_week+ coord_flip(ylim=c(-0.65,0.65)) + theme(panel.grid.major.y = element_line(colour = "grey95"), panel.grid.minor.y = element_line(colour = "grey90"))
ggsave("figures/fig_WeekResid_SubjectiveStress.tiff",units="in", width=4, height=4, dpi=300, compression = 'lzw', bg="transparent")
```


### Mood {.tabset}

Next, we want to investigate the impact of an examination period on mood. Conceptually, mood is an outcome of being stressed, and not a direct measure of stress. Below are the results of the models for both positive and negative mood.

#### Positive{-}

```{r warning=FALSE}
# Model
# glmer.posmood_week <- glmer( mood_positive_s ~ Week_Type +  #Model week
#     Sex + Program +  # Model sex and program 
#     First_Week + ema_day*ema_beep_f + # Model day related items
#     physical_excercise_dur + acc_delta + acc_delta*physical_excercise_dur + # Model movement
#     (1+Week_Type|castor_record_id) + (0+acc_delta|castor_record_id) + 
#     (0+ema_survey|castor_record_id) + (0+physical_excercise_dur|castor_record_id) + 
#     (1|castor_record_id:ema_day:ema_beep_f),
#     data=EMA_Data,
#     family=gaussian(link="log"),
#     control=glmerControl(calc.derivs = FALSE))

# Model Summary
model_output(glmer.posmood_week)

```

####  Negative{-}

```{r warning=FALSE}
# Model
# glmer.negmood_week <- glmer( mood_negative_s ~  Week_Type +  #Model week
#     Sex + Program +  # Model sex and program 
#     First_Week + ema_day*ema_beep_f + # Model day related items
#     physical_excercise_dur + acc_delta + acc_delta*physical_excercise_dur + # Model movement
#     (1+Week_Type|castor_record_id) + (0+acc_delta|castor_record_id) + 
#     (0+ema_survey|castor_record_id) + (0+physical_excercise_dur|castor_record_id) + 
#     (1|castor_record_id:ema_day:ema_beep_f),
#     data=EMA_Data,
#     family=Gamma(link="log"),
#     control=glmerControl(calc.derivs = FALSE))

# Model Summary
model_output(glmer.negmood_week) 

```

#### Results: Mood vs Subjective Stress{-}

```{r}
table.mood_week <- tab_model(glmer.posmood_week, glmer.negmood_week,
          terms=c("(Intercept)","Week_Type [Stress]", "Sex [Male]", "Program [BSc_Med]", "First_Week [Exam-First]", "acc_delta", "physical_excercise_dur"), 
          dv.labels=c("Positive", "Negative"), 
          title="Table 2. Mood vs Week Type", 
          transform=NULL, 
         show.stat=TRUE,
         show.se=TRUE)
htmlTable::htmlTable(table.mood_week$knitr)
```



### Phyisiology Stress

We established changes in subjective stress between the weeks, which has an impact on our mood outcomes. We also want to see if there's a general difference between the physiology variables and the weeks.To do this we apply the same approach for the physiology measures as the other models. We also add measures of skin temperature here however, to make sure that we factor this in. Skin temperature is important as it can be related to sweat or heat, which can also lead to increased arousal measures. 

#### Skin Conductance {.tabset .tabset-fade}

First we model the skin conductance, controlling for skin temperature and physical exercise.

##### Tonic SC {-} 

```{r warning=TRUE}
# # Model
# glmer.sc_ton_mean_week <- glmer( sc_tonic_mean_s ~ Week_Type + 
#     Sex + Program + # Model pop differences
#     First_Week +  ema_beep_f*ema_day + # Model day related differencxes
#     physical_excercise_dur + acc_delta + # Modle movement stuff
#     temp_mean_z + temp_slope_z +  # Model temp effects
#     (1+Week_Type |castor_record_id) + 
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id) + 
#     (0+physical_excercise_dur|castor_record_id) + (0+acc_delta|castor_record_id) + 
#     (1 | castor_record_id:ema_day:ema_beep_f), 
#     EMA_Data, 
#     family=Gamma(link="log"),
#     control=glmerControl(calc.derivs = FALSE, optCtrl=list(maxfun=100000)))

# Model Summary
model_output(glmer.sc_ton_mean_week)


```


##### Phasic Num {-}

```{r warning=FALSE}
# Model
# glmer.sc_ph_num <- glmer( sc_phasic_num ~  Week_Type + 
#     Sex + Program + # Model pop differences
#     First_Week +  ema_beep_f*ema_day + # Model day related differencxes
#     physical_excercise_dur + acc_delta + # Modle movement stuff
#     temp_mean_z + temp_slope_z +  # Model temp effects
#     (1+Week_Type |castor_record_id) + 
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id) + 
#     (0+physical_excercise_dur|castor_record_id) + (0+acc_delta|castor_record_id) + 
#     (1 | castor_record_id:ema_day:ema_beep_f),  
#     EMA_Data, 
#     family=poisson(link="log"),
#     control=lmerControl(calc.derivs = FALSE) )

# Model Summary
model_output(glmer.sc_ph_num)

```



##### Phasic Magnitude {-}
```{r warning=FALSE}
# Model
# glmer.sc_ph_mag <- glmer( sc_phasic_mag_s ~ Week_Type + 
#     Sex + Program + # Model pop differences
#     First_Week +  ema_beep_f*ema_day + # Model day related differencxes
#     physical_excercise_dur +acc_delta + # Modle movement stuff
#     temp_mean_z + temp_slope_z +  # Model temp effects
#     (1+Week_Type |castor_record_id) + 
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id) + 
#     (0+physical_excercise_dur|castor_record_id) + (0+acc_delta|castor_record_id) + 
#     (1 | castor_record_id:ema_day:ema_beep_f), 
#     EMA_Data, 
#     family=Gamma(link="identity"),
#     control=glmerControl(calc.derivs = FALSE) )

# Model Summary
model_output(glmer.sc_ph_mag)

```



##### Phasic AUC {-}

```{r}
# Model
# glmer.sc_ph_auc_week <- glmer( sc_phasic_auc_s  ~ Week_Type + 
#     Sex + Program + # Model pop differences
#     First_Week +  ema_beep_f*ema_day + # Model day related differencxes
#     physical_excercise_dur +acc_delta + # Modle movement stuff
#     temp_mean_z + temp_slope_z +  # Model temp effects
#     (1+Week_Type |castor_record_id) + 
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id) + 
#     (0+physical_excercise_dur|castor_record_id) + (0+acc_delta|castor_record_id) + 
#     (1 | castor_record_id:ema_day:ema_beep_f), 
#     EMA_Data, 
#     family=Gamma(link=log),
#     control=glmerControl(calc.derivs = FALSE, optCtrl=list(maxfun=100000)))

# Model Summary
model_output(glmer.sc_ph_auc_week)

``` 


#### Heart Rate {.tabset}

Next We check the heart rate data. It again looks like the relationship of the models is not as expected.

##### HR Mean {-}

```{r}
# Model
# glmer.hr_mean_week <- glmer( hr_mean_s ~ Week_Type + 
#     Sex + Program + # Model pop differences
#     First_Week +  ema_beep_f*ema_day + # Model day related differencxes
#     physical_excercise_dur +acc_delta + # Modle movement stuff
#     temp_mean_z + temp_slope_z +  # Model temp effects
#     (1+Week_Type |castor_record_id) + 
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id) + 
#     (0+physical_excercise_dur|castor_record_id) + (0+acc_delta|castor_record_id) + 
#     (1 | castor_record_id:ema_day:ema_beep_f), 
#     EMA_Data, 
#     family=Gamma(link=identity),
#    control=glmerControl(calc.derivs = FALSE, optCtrl=list(maxfun=100000)))

# Model Summary
model_output(glmer.hr_mean_week)

```


##### HR Max {-}

```{r}
# Model
# glmer.hr_max_week <- glmer( hr_max_s  ~ Week_Type + 
#     Sex + Program + # Model pop differences
#     First_Week +  ema_beep_f*ema_day + # Model day related differencxes
#     physical_excercise_dur +acc_delta + # Modle movement stuff
#     temp_mean_z + temp_slope_z +  # Model temp effects
#     (1+Week_Type |castor_record_id) + 
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id) + 
#     (0+physical_excercise_dur|castor_record_id) + (0+acc_delta|castor_record_id) + 
#     (1 | castor_record_id:ema_day:ema_beep_f),  
#     EMA_Data, 
#     family=Gamma(link="identity"),
#     control=glmerControl(calc.derivs = FALSE, optCtrl=list(maxfun=100000)))

# Model SUmmary
model_output(glmer.hr_max_week)

```


##### HR Min {-}

```{r}
# Model
# glmer.hr_min_week <- glmer( hr_min_s  ~ Week_Type + 
#     Sex + Program + # Model pop differences
#     First_Week +  ema_beep_f*ema_day + # Model day related differencxes
#     physical_excercise_dur +acc_delta + # Modle movement stuff
#     temp_mean_z + temp_slope_z +  # Model temp effects
#     (1+Week_Type |castor_record_id) + 
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id) + 
#     (0+physical_excercise_dur|castor_record_id) + (0+acc_delta|castor_record_id) + 
#     (1 | castor_record_id:ema_day:ema_beep_f), 
#     EMA_Data, 
#     family=Gamma(link="identity"),
#     control=glmerControl(calc.derivs = FALSE, optCtrl=list(maxfun=100000)))

# Model Summary
model_output(glmer.hr_min_week)

```



#### Results: Physiology vs Weektype
We now present the physiology results in a table, corrected for multiple comparisons with FDR.
```{r}
table.physio_week <- tab_model(glmer.sc_ton_mean_week, glmer.sc_ph_num, glmer.sc_ph_mag, glmer.sc_ph_auc_week,
                           glmer.hr_mean_week, glmer.hr_min_week, glmer.hr_max_week, 
         terms=c("(Intercept)","Week_Type [Stress]", "Sex [Male]", "Program [BSc_Med]", "First_Week [Exam-First]", "acc_delta", "physical_excercise_dur", 
         "temp_mean_z", "temp_slope_z"), 
          dv.labels=c("Tonic", "Number", "Magnitude", "AUC", "Mean", "Min", "Max"), 
          title="Table 3. Physio vs Week Type", 
          transform=NULL, p.adjust="fdr",
         show.stat=TRUE,
         show.se=T) 
htmlTable::htmlTable(table.physio_week$knitr)
```



### Plot: Week v Outcomes
Finally, we can plot the estimates for the week differences here, also correcting for multiple comparisons with FDR.
```{r}
# Together
plot.physio <- plot_models(glmer.posmood_week, glmer.sc_ton_mean_week, glmer.sc_ph_num)
rm_term <- as.vector(plot.physio$data$term[1:97])
rm_term <- rm_term[rm_term != "Week_TypeStress"]
# Color list
col_list <-c('#7570B3','#7570B3','#7570B3',"#D95F02", "#D95F02", '#D95F02', '#D95F02', "#1B9E77", "#1B9E77")

# Make the plot
plot.all_week_resid <- plot_models( glmer.posmood_week, glmer.negmood_week, 
            glmer.sc_ton_mean_week, glmer.sc_ph_num, glmer.sc_ph_mag, glmer.sc_ph_auc_week, 
            glmer.hr_mean_week, glmer.hr_min_week, glmer.hr_max_week,
            m.labels=c("Positive Affect", "Negative Affect", "SC Tonic", "SC Number", "SC Magnitued", "SC AUC","HR Mean", "HR Minimum", "HR Maximum"),
            axis.labels = c(" "),
            # Stastistical Stuff
            rm.terms = rm_term,
            #show.values = T,
            #value.size = 4, 
            #std.est=T, 
            show.p=T,
            p.shape=T,
            p.adjust = "fdr", 
            legend.pval.title = "Significance", 
            # Visual Stuff
            colors=col_list,
            dot.size=2,
            line.size = 1,
            spacing=0.7, 
            vline.color = "darkgrey", 
            legend.title = "") + 
            ptheme + 
            theme(axis.ticks.y=element_blank(), 
                  legend.text=element_text(size=16), legend.title = element_text(size=16),
                  axis.title = element_text(size=16),axis.text.x=element_text(size=11),
                  panel.grid.major.x = element_line(colour = "grey95"),
                  panel.grid.minor.x = element_line(colour = "grey90")) 

# Plot and save
plot.all_week_resid + coord_flip(ylim=c(-0.5,0.5)) + theme(panel.grid.major.y = element_line(colour = "grey95"), panel.grid.minor.y = element_line(colour = "grey90"))
ggsave("figures/fig_WeekResid_ALL.tiff", units="in", width=4, height=4, dpi=300, compression = 'lzw', bg="transparent")
```



## Momentary Associations

We saw lower physiological arousal in the exam week, which was unexpected. We also see lower positive arousal. So it could be that the effects we see are actually driven by our positive arousal/mood. To check this, and to also check whether we can replicate previous indings on moment-to-moment associations between subjective stress and physiological arousal and mood, we discard week type, and look at the measure continuously. 

In this models, we use a fixed slope due to convergence issues. We initially tried changing optimizers, which did not result in better convergence, so we simplified the model by doing a fixed slope for our fixed effect of interest. We again use more or less the same covariates as before, except for program, and for day. We keep the time variable in there to control for circadian rhythms. Additionally, we see there is a correlation between our subjective stress measures, so we need to factor this effect in by modeling interaction terms as well. 

```{r}
 rcorr(as.matrix(EMA_Data[,c("event_tot_s", "activity_tot_s", "social_tot_s", "physical_tot_s")]))
```

### Mood {.tabset}

First we check the moment-to-moment associations between positive affect and subjective stress. These confirm that momentary subjective stress is also associated with reduced positive affect, and increased negative affect.

#### Positive {-}
```{r}

# glmer.posmood_beep <- lmer(mood_positive_s ~ 
#     event_tot_s*activity_tot_s + activity_tot_s*social_tot_s + physical_tot_s +
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex +  physical_excercise_dur + acc_delta +
#     temp_mean_z + temp_slope_z + 
#     (0+event_tot_s+activity_tot_s+social_tot_s+physical_tot_s | castor_record_id) + 
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#    # family=gaussian(link="identity"),
#     control=lmerControl(calc.derivs = FALSE) )

# Summary
model_output(glmer.posmood_beep )

```

#### Negative {-}

```{r}
# glmer.negmood_beep <- glmer(mood_negative_s ~ 
#     event_tot_s*activity_tot_s + activity_tot_s*social_tot_s + physical_tot_s +
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex +  physical_excercise_dur + acc_delta +
#     temp_mean_z + temp_slope_z + 
#     (0+event_tot_s+activity_tot_s+social_tot_s+physical_tot_s | castor_record_id) + 
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=Gamma(link="identity"),
#     control=glmerControl(calc.derivs = FALSE) )

# Summary
model_output(glmer.negmood_beep)
```

#### Table: Mood per Beep {-}
```{r}
table.mood_beep <- tab_model(glmer.posmood_beep, glmer.negmood_beep,
         # terms=c("(Intercept)","Week_Type [Stress]", "Sex [Male]", "Program [BSc_Med]", "First_Week [Exam-First]", "acc_delta", "physical_excercise_dur"), 
          title="Table 3. HR vs Week Type", 
          transform=NULL, p.adjust = "fdr",
         show.stat=TRUE,
         show.se=TRUE) 
htmlTable::htmlTable(table.mood_beep$knitr)
```



### Skin conductance {.tabset}

We next model the skin conductance vs. the subjective stress measures. We expect that continuous analysis will result in a replication of previous findings where momentary stress is indeed associated with increase physiological arousal. Our findings are indeed shown in [Table: Subjective Stress and Outcomes].

#### Tonic Mean {-}

```{r}
# Model
# glmer.sc_ton_ema <- glmer(sc_tonic_mean_s ~ 
#     event_tot_s*activity_tot_s + activity_tot_s*social_tot_s + physical_tot_s +
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex +  physical_excercise_dur + acc_delta +
#     temp_mean_z + temp_slope_z + 
#     (0+event_tot_s+activity_tot_s+social_tot_s+physical_tot_s | castor_record_id) + 
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=Gamma(link="log"),
#     control=glmerControl(calc.derivs = FALSE) )

# Summary
model_output(glmer.sc_ton_ema)
```


#### Phasic Number {-}
```{r}
# Model
# glmer.sc_ph_num_ema <- glmer(sc_phasic_num  ~ 
#     event_tot_s*activity_tot_s + activity_tot_s*social_tot_s + physical_tot_s +
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex +  physical_excercise_dur + acc_delta +
#     temp_mean_z + temp_slope_z + 
#     (0+event_tot_s+activity_tot_s+social_tot_s+physical_tot_s | castor_record_id) + 
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=poisson(link="sqrt"),
#     control=glmerControl(calc.derivs = FALSE) )

# Model Summary
model_output(glmer.sc_ph_num_ema)
```


#### Phasic Magnitude {-}

```{r}
# Model
# glmer.sc_ph_mag_ema <- glmer(sc_phasic_mag_s   ~
#     event_tot_s*activity_tot_s + activity_tot_s*social_tot_s + physical_tot_s +
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex +  physical_excercise_dur + acc_delta +
#     temp_mean_z + temp_slope_z + 
#     (0+event_tot_s+activity_tot_s+social_tot_s+physical_tot_s | castor_record_id) + 
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=Gamma(link="identity"),
#     control=glmerControl(calc.derivs = FALSE, optCtrl=list(maxfun=100000)))

# Model Summary
model_output(glmer.sc_ph_mag_ema)
```


#### Phasic AUC {-}

```{r}
# Model
# glmer.sc_ph_auc_ema <- glmer(sc_phasic_auc_s  ~
#      event_tot_s*activity_tot_s + activity_tot_s*social_tot_s + physical_tot_s +
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex +  physical_excercise_dur + acc_delta +
#     temp_mean_z + temp_slope_z + 
#     (0+event_tot_s+activity_tot_s+social_tot_s+physical_tot_s | castor_record_id) + 
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=Gamma(link="identity"),
#     control=glmerControl(calc.derivs = FALSE) )

# Model Summary
model_output(glmer.sc_ph_auc_ema)
```


### Heart Rate{.tabset}

Finally, we also take a look at subjective stress associations with subjective stress. Here we do not see any striking relationships. 

#### Mean {-}

```{r}
# Model
# glmer.hr_mean_ema <- glmer(hr_mean_s ~
#     event_tot_s*activity_tot_s + activity_tot_s*social_tot_s + physical_tot_s +
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex +  physical_excercise_dur + acc_delta +
#     temp_mean_z + temp_slope_z + 
#     (0+event_tot_s+activity_tot_s+social_tot_s+physical_tot_s | castor_record_id) + 
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=Gamma(link="identity"),
#    control=glmerControl(calc.derivs = FALSE, optCtrl=list(maxfun=100000)))

# Model Summary
model_output(glmer.hr_mean_ema)
```


#### Min {-}

```{r}
# Model
# glmer.hr_min_ema <- glmer(hr_min_s  ~
#     event_tot_s*activity_tot_s + activity_tot_s*social_tot_s + physical_tot_s +
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex +  physical_excercise_dur + acc_delta +
#     temp_mean_z + temp_slope_z + 
#     (0+event_tot_s+activity_tot_s+social_tot_s+physical_tot_s | castor_record_id) + 
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=Gamma(link="log"),
#     control=glmerControl(calc.derivs = FALSE) )

# Model Summary
model_output(glmer.hr_min_ema)
```


#### Max {-}

```{r}
# Model
# glmer.hr_max_ema <- glmer(hr_max_s ~
#     event_tot_s*activity_tot_s + activity_tot_s*social_tot_s + physical_tot_s +
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex +  physical_excercise_dur + acc_delta +
#     temp_mean_z + temp_slope_z + 
#     (0+event_tot_s+activity_tot_s+social_tot_s+physical_tot_s | castor_record_id) + 
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=Gamma(link="identity"),
#     control=glmerControl(calc.derivs = FALSE) )

# Model Summary
model_output(glmer.hr_max_ema)

```



### Table: Subjective Stress and Outcomes

```{r}
table.physio_beep <- tab_model(glmer.sc_ton_ema, glmer.sc_ph_num_ema, glmer.sc_ph_mag_ema, glmer.sc_ph_auc_ema, 
            glmer.hr_mean_ema, glmer.hr_min_ema, glmer.hr_max_ema, 
          dv.labels=c("SC Tonic", "SC Number", "SC Magnitude", "SC AUC", "Mean", "Min", "Max"), 
          title="Table X. Momentary Physiology and Subjective Stress",
            transform=NULL, p.adjust="fdr", 
         show.stat=TRUE,
         show.se=TRUE) 
htmlTable::htmlTable(table.physio_beep$knitr)
```

### Plot: Outcomes v Subjective Stress

Next I want to plot our outcomes as a function of the subjective stress. I will do this in separate graphs for event, activity, social, and physical stress. This gets a little complicated though. So I will make each graph separately, and then combine them outside of R to make sure they still look good. 
```{r}
# Shorrtlist the variables to those of interest
plot.vars <- plot_models(glmer.posmood_beep, glmer.sc_ph_num_ema, glmer.hr_mean_ema, glmer.hr_min_ema, glmer.hr_max_ema)
# Get and filter terms
full_term <- as.vector(plot.vars$data$term[1:length(plot.vars$data$term)])
event_term <- full_term[full_term != "event_tot_s"]
activ_term <-full_term[full_term != "activity_tot_s"]
soc_term <- full_term[full_term != "social_tot_s"]
phy_term <- full_term[full_term != "physical_tot_s"]
# Set the colours
col_list <-c('#7570B3','#7570B3','#7570B3',"#D95F02", "#D95F02", '#D95F02', '#D95F02', "#1B9E77", "#1B9E77")

# Event Plot
plot.event_substr <- plot_models(glmer.posmood_beep, glmer.negmood_beep, 
            glmer.sc_ton_ema, glmer.sc_ph_num_ema, glmer.sc_ph_mag_ema, glmer.sc_ph_auc_ema, 
            glmer.hr_mean_ema, glmer.hr_min_ema, glmer.hr_max_ema, 
            m.labels=c("Positive Affect", "Negative Affect", "SC Tonic", "SC Number", "SC Magnitued", "SC AUC", "HR Mean", "HR Minimum", "HR Maximum"),
            axis.labels = c(""), 
            # Stastistical Stuff
            rm.terms = event_term,
            #show.values = T,
            #value.size = 4, 
            #std.est=T, 
            show.p=T,
            p.shape=T,
            p.adjust = "fdr", 
            legend.pval.title = "Significance", 
            # Visual Stuff
            colors=col_list,
            dot.size=2,
            line.size = 0.5,
            spacing=0.7, 
            vline.color = "darkgrey", 
            legend.title = "") + 
            ptheme + 
            theme(axis.ticks.y=element_blank(), 
                  axis.title = element_text(size=16),axis.text.x=element_text(size=11),
                  panel.grid.major.x = element_line(colour = "grey95"),
                  panel.grid.minor.x = element_line(colour = "grey90")) 
plot.event_substr <- plot.event_substr+ coord_flip(ylim=c(0.75,1.25)) +  coord_flip(ylim=c(-0.5,0.5)) + theme(panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank())
ggsave("figures/fig_StrResid_Event.tiff", units="in", width=4, height=4, dpi=300, compression = 'lzw', bg="transparent")

# Act Plot
plot.activity_substr <-  plot_models(glmer.posmood_beep, glmer.negmood_beep, 
            glmer.sc_ton_ema, glmer.sc_ph_num_ema, glmer.sc_ph_mag_ema, glmer.sc_ph_auc_ema, 
            glmer.hr_mean_ema, glmer.hr_min_ema, glmer.hr_max_ema, 
            m.labels=c("Positive Affect", "Negative Affect", "SC Tonic", "SC Number", "SC Magnitued", "SC AUC", "HR Mean", "HR Minimum", "HR Maximum"),
            axis.labels = c(""), 
            # Stastistical Stuff
            rm.terms = activ_term,
            #show.values = T,
            #value.size = 4, 
            #std.est=T, 
            show.p=T,
            p.shape=T,
            p.adjust = "fdr", 
            legend.pval.title = "Significance", 
            # Visual Stuff
            colors=col_list,
            dot.size=2,
            line.size = 0.5,
            spacing=0.7, 
            vline.color = "darkgrey", 
            legend.title = "") + 
            ptheme + 
              theme(axis.ticks.y=element_blank(), 
                  axis.title = element_text(size=16),axis.text.x=element_text(size=11),
                  panel.grid.major.x = element_line(colour = "grey95"),
                  panel.grid.minor.x = element_line(colour = "grey90")) 
plot.activity_substr <- plot.activity_substr+ coord_flip(ylim=c(0.75,1.25)) +  coord_flip(ylim=c(-0.5,0.5)) + theme(panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank())
ggsave("figures/fig_StrResid_Activity.tiff", units="in", width=4, height=4, dpi=300, compression = 'lzw', bg="transparent")


# Social Stress
plot.social_substr <-  plot_models(glmer.posmood_beep, glmer.negmood_beep, 
            glmer.sc_ton_ema, glmer.sc_ph_num_ema, glmer.sc_ph_mag_ema, glmer.sc_ph_auc_ema, 
            glmer.hr_mean_ema, glmer.hr_min_ema, glmer.hr_max_ema, 
            m.labels=c("Positive Affect", "Negative Affect", "SC Tonic", "SC Number", "SC Magnitued", "SC AUC", "HR Mean", "HR Minimum", "HR Maximum"),
            axis.labels = c(""), 
            # Stastistical Stuff
            rm.terms = soc_term,
            #show.values = T,
            #value.size = 4, 
            #std.est=T, 
            show.p=T,
            p.shape=T,
            p.adjust = "fdr", 
            legend.pval.title = "Significance", 
            # Visual Stuff
            colors=col_list,
            dot.size=2,
            line.size = 0.5,
            spacing=0.7, 
            vline.color = "darkgrey", 
            legend.title = "") + 
            ptheme + 
            theme(axis.ticks.y=element_blank(), 
                  axis.title = element_text(size=16),axis.text.x=element_text(size=11),
                  panel.grid.major.x = element_line(colour = "grey95"),
                  panel.grid.minor.x = element_line(colour = "grey90")) 
## Plot
plot.social_substr <- plot.social_substr + coord_flip(ylim=c(0.75,1.25)) +  coord_flip(ylim=c(-0.5,0.5)) + theme(panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank())
ggsave("figures/fig_StrResid_Social.tiff", units="in", width=4, height=4, dpi=300, compression = 'lzw', bg="transparent")

# Physical Stress
plot.physical_substr <- plot_models(glmer.posmood_beep, glmer.negmood_beep, 
            glmer.sc_ton_ema, glmer.sc_ph_num_ema, glmer.sc_ph_mag_ema, glmer.sc_ph_auc_ema, 
            glmer.hr_mean_ema, glmer.hr_min_ema, glmer.hr_max_ema, 
            m.labels=c("Positive Affect", "Negative Affect", "SC Tonic", "SC Number", "SC Magnitued", "SC AUC", "HR Mean", "HR Minimum", "HR Maximum"),
            axis.labels = c(""), 
            # Stastistical Stuff
            rm.terms = phy_term,
            #show.values = T,
            #value.size = 4, 
            #std.est=T, 
            show.p=T,
            p.shape=T,
            p.adjust = "fdr", 
            legend.pval.title = "Significance", 
            # Visual Stuff
            colors=col_list,
            dot.size=2,
            line.size =0.5,
            spacing=0.7, 
            vline.color = "darkgrey", 
            legend.title = "") + 
            ptheme + 
              theme(axis.ticks.y=element_blank(), 
                  axis.title = element_text(size=16),axis.text.x=element_text(size=11),
                  panel.grid.major.x = element_line(colour = "grey95"),
                  panel.grid.minor.x = element_line(colour = "grey90")) 
# Plot
plot.physical_substr <- plot.physical_substr +  coord_flip(ylim=c(-0.5,0.5), xlim=c(1,1.1)) + theme(panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank())
ggsave("figures/fig_StrResid_Physical.tiff", units="in", width=4, height=4, dpi=300, compression = 'lzw', bg="transparent")

# All
ggarrange(plot.event_substr, plot.activity_substr, plot.social_substr, plot.physical_substr, common.legend = T, legend="right")
ggsave("figures/fig_StrResid_MAT.tiff", units="in", width=7, height=7, dpi=300, compression = 'lzw', bg="transparent")
```

## Mood and Physiology

Arousal is not a valence specific mechanism. In the stress week, we see that there is a reduction in our physiological arousal measures, but also in positive affect. To this end, we check the relationship between physiology and the mood items. We expect that while arousal measures are indeed associated with stress, they are also associated with positive mood. 
To this end, we model these relationships with both positive and negative affect. We use a maximal fitting approach as before.  We see a high correlation between positive and negative mood (presented below), and therefore also model interaction terms here. Due to model convergence issues, we only model the fixed intercepts here for the fixed effects of interest. Again, we check all model families before we pick the one with the best fit. 

```{r}
 rcorr(as.matrix(EMA_Data[,c("mood_positive_s", "mood_negative_s")]))
```

### Skin Conductance {.tabset}

#### Mean {-}
```{r}
# Model
# glmer.sc_ton_mood <- glmer(sc_tonic_mean_s ~ mood_positive_s*mood_negative_s + 
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex + temp_slope_z + temp_mean_z + 
#     acc_delta + physical_excercise_dur +
#     (0+mood_positive_s*mood_negative_s| castor_record_id) +# + (1+mood_negative_s|castor_record_id)+
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=Gamma(link="log"),
#     control=glmerControl(calc.derivs = FALSE) )

# Summary
model_output(glmer.sc_ton_mood)

```

#### Number {-}
```{r}
# Model
# glmer.sc_phnum_mood <- glmer(sc_phasic_num_s ~ mood_positive_s*mood_negative_s + 
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex + temp_slope_z + temp_mean_z + 
#     acc_delta + physical_excercise_dur +
#     (1+mood_positive_s*mood_negative_s| castor_record_id) +# + (1+mood_negative_s|castor_record_id)+
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=Gamma(link="identity"),
#     control=glmerControl(calc.derivs = FALSE) )

# Summary
model_output(glmer.sc_phnum_mood)
```

#### Magnitude {-}
```{r}
# Model
# glmer.sc_ph_mag_mood <- glmer(sc_phasic_mag_s ~ mood_positive_s*mood_negative_s + 
#     ema_beep + 
#     Sex + temp_slope_z + temp_mean_z + 
#     acc_delta + physical_excercise_dur +
#     (1+mood_positive_s*mood_negative_s| castor_record_id)  + 
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#    family=Gamma(link="identity"),
#     control=glmerControl(calc.derivs = FALSE, optCtrl=list(maxfun=100000) ))

# Summary
model_output(glmer.sc_ph_mag_mood)
```


#### AUC {-}
```{r}
# Model
# glmer.sc_ph_auc_mood <- glmer(sc_phasic_auc_s ~ mood_positive_s*mood_negative_s + 
#     ema_beep + 
#     Sex + temp_slope_z + temp_mean_z + 
#     acc_delta + physical_excercise_dur +
#     (1+mood_positive_s*mood_negative_s| castor_record_id)  +
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=Gamma(link="log"),
#     control=glmerControl(calc.derivs = FALSE) )

# Summary
model_output(glmer.sc_ph_auc_mood)
```


### Heart Rate {.tabset}

#### Mean {-}
```{r}

# glmer.hr_mean_mood <- glmer(hr_mean_s ~ mood_positive_s*mood_negative_s + 
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex + temp_slope_z + temp_mean_z + 
#     acc_delta + physical_excercise_dur +
#     (1+mood_positive_s*mood_negative_s| castor_record_id)  + # (1+mood_positive_s| castor_record_id) + (1+mood_negative_s|castor_record_id)+
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=Gamma(link="log"),
#     control=glmerControl(calc.derivs = FALSE) )

# Summary
model_output(glmer.hr_mean_mood )

```


#### Min {-}
```{r}
# glmer.hr_min_mood <- glmer(hr_min_s ~ mood_positive_s*mood_negative_s + 
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex + temp_slope_z + temp_mean_z + 
#     acc_delta + physical_excercise_dur +
#     (1+mood_positive_s*mood_negative_s| castor_record_id)  + # (1+mood_positive_s| castor_record_id) + (1+mood_negative_s|castor_record_id)+
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=Gamma(link="log"),
#     control=glmerControl(calc.derivs = FALSE) )

# Summary
model_output(glmer.hr_min_mood )

```

#### Max {-}
```{r}
# glmer.hr_max_mood <- glmer(hr_max_s ~ mood_positive_s*mood_negative_s + 
#     ema_beep + # I will model the beep to factor circadian rhythms
#     Sex + temp_slope_z + temp_mean_z + 
#     acc_delta + physical_excercise_dur +
#     (1+mood_positive_s*mood_negative_s| castor_record_id)  + # (1+mood_positive_s| castor_record_id) + (1+mood_negative_s|castor_record_id)+
#     (0+ema_beep|castor_record_id)+
#     (0+temp_slope_z|castor_record_id) + (0+temp_mean_z|castor_record_id)+
#     (0+acc_delta|castor_record_id) + (0+physical_excercise_dur|castor_record_id),
#     EMA_Data,
#     family=Gamma(link="log"),
#    control=glmerControl(calc.derivs = FALSE, #, optimizer="Nelder_Mead",
#                          optCtrl=list(maxfun=100000)) )

# Summary
model_output(glmer.hr_max_mood )
```


### Results: Mood and Physiology
```{r}
table.physio_mood <- tab_model(glmer.sc_ton_mood, glmer.sc_phnum_mood, glmer.sc_ph_mag_mood, glmer.sc_ph_auc_mood,
                glmer.hr_mean_mood, glmer.hr_min_mood, glmer.hr_max_mood,
          dv.labels=c("SC Tonic", "SC Number", "SC Magnitude", "SC AUC", "HR Mean", "HR Min", "HR Max"), 
          title="Table X. Physio vs. Mood",
            transform=NULL, p.adjust="fdr", 
         show.stat=TRUE,
         show.se=TRUE)
htmlTable::htmlTable(table.physio_mood$knitr)
```


```{r}
# Subset variables of interests
plot.physio <- plot_models(glmer.sc_ton_mood, glmer.sc_phnum_mood, glmer.hr_mean_mood)
rm_term <- as.vector(plot.physio$data$term[1:97])
rm_term <- rm_term[rm_term != "mood_positive_s" & rm_term!="mood_negative_s"]
# Set the colours
col_list <-c('#7570B3','#7570B3','#7570B3',"#D95F02", "#D95F02", '#D95F02', '#D95F02', "#1B9E77", "#1B9E77")


# Make the plot
plot.pos_mood_resid <- plot_models( glmer.sc_ton_mood, glmer.sc_phnum_mood, glmer.sc_ph_mag_mood, glmer.sc_ph_auc_mood,
                glmer.hr_mean_mood, glmer.hr_min_mood, glmer.hr_max_mood,
              m.labels=c("SC Tonic", "SC Number", "SC Magnitued", "SC AUC","HR Mean", "HR Minimum", "HR Maximum"),
           axis.labels = c(" "),
            # Stastistical Stuff
           transform=NULL,
            rm.terms = rm_term,
            #show.values = T,
            #value.size = 4, 
            #std.est=T, 
            show.p=T,
            p.shape=T,
            p.adjust = "fdr", 
            legend.pval.title = "Significance", 
            # Visual Stuff
            colors=col_list,
            dot.size=2,
            line.size = 1,
            spacing=0.7, 
            vline.color = "darkgrey", 
            legend.title = "") + 
            ptheme + scale_y_continuous(breaks=c( -0.2, -.1,0, .1,.2)) + 
            theme(axis.ticks.y=element_blank(), 
                  axis.title = element_text(size=16),axis.text.x=element_text(size=11),
                  panel.grid.major.x = element_line(colour = "grey95"),
                  panel.grid.minor.x = element_line(colour = "grey90")) 
# Plot and Save
plot.pos_mood_resid + coord_flip(ylim=c(-.25,.25)) + theme(panel.grid.major.y = element_line(colour = "grey95"), panel.grid.minor.y = element_line(colour = "grey90"))
ggsave("figures/fig_MoodkResid_ALL.tiff", units="in", width=5, height=5, dpi=300, compression = 'lzw', bg="transparent")
```


## Mediation anaylsis

In the stress week, we see a decrease in both positive mood and physiology. However, we also see an increase in stress during this time too. This is confusing given the moment to moment relationship between subjective stress and physiology. One potential explanation is that the physiology is more strongly associate with positive arousal and opposed to negative arousal. So we need to actually confirm that what we see in the stress week (i.e. the physiology arousal decrease) is actually due to the positive mood changes. To this end, we perfrom a mediation analysis. We first need to filter out the nan's here for some reason though. We cant apply this analysis to mixed level models, so we instead just check the simple models here.

```{r}
library(mediation)
set.seed(123)

EMA_Sub <- EMA_Data %>% dplyr::select(castor_record_id, Week_Type, sc_phasic_mag_s, sc_phasic_num_s, mood_positive_s, event_tot_s,  Sex, Program, # Model pop differences
    First_Week,  ema_beep_f, ema_day, 
    physical_excercise_dur, acc_delta, 
    temp_mean_z,temp_slope_z) %>% filter(complete.cases(.))
```

Two arousal measures were reduced in the stress week, but also associated with increased subjective stress. These measures were the **number of skin conductance responses** and the **magnitude of skin conductance responses**. So here we will check the mediating effect of positive mood. 

### SC Number
First we check whether positive mood mediates the effects of week type of the number of responses. We see in the control week, there is a trend with positive affect mediating  the number of skin conductace responses. 
```{r}
# Main effe
fit.totaleffect=glmer(sc_phasic_num_s ~ Week_Type + (1|castor_record_id), EMA_Sub)
#summary(fit.totaleffect)

# Mediations
fit.mediator=glmer(mood_positive_s ~ Week_Type + (1|castor_record_id), EMA_Sub)
#summary(fit.mediator)

# Combined
fit.dv=glmer(sc_phasic_num_s ~ Week_Type*mood_positive_s + (1|castor_record_id), EMA_Sub)
#summary(fit.dv)

# Mediation analysis
results1 = mediate(model.m=fit.mediator, model.y=fit.dv, treat='Week_Type', mediator='mood_positive_s', sims=5000, control.value="Control", treat.value="Stress")
summary(results1)

```

### SC Magnitude
We next check the mediating effect of positive affect on skin coductance magnitde. Here we see that the magnitude of the responses is significanlty mediated by positive affect. It seems in both cases, these effects are being driven by the control week.
```{r}
# Main effect
fit.totaleffect=glmer(sc_phasic_mag_s ~ Week_Type  + (1|castor_record_id), EMA_Sub)
summ(fit.totaleffect)

# Mediations
fit.mediator=glmer(mood_positive_s ~ Week_Type  +  (1|castor_record_id), EMA_Sub)
summ(fit.mediator)

# Combined
fit.dv=glmer(sc_phasic_mag_s ~ Week_Type*mood_positive_s + (1|castor_record_id), EMA_Sub)
summ(fit.dv)

# Mediation analysis
results2 = mediate(model.m=fit.mediator, model.y=fit.dv, treat='Week_Type', mediator='mood_positive_s', boot=F, sims=5000)
summary(results2)

```

# Random Forests

We were able to establish that physiology and mood both change in the weeks under chronic stress. That is good, because now we can see how well we can use this information in predictive models. To this end, we use the randomForest package plus some extra functions to test our prediction. The point of this analysis is to determine whether was can use the EPA/wristwatch measures on their own to classify which week participants are in, and to additionally check whether this would be as good as asking about mood. Finally, we will see whether the combination of both the mood and EPA measures is actually the best option. 

Before we begin, we load the required library, and preset the seed to keep the analysis consistent. We additionally filter out the incomplete datapoints on only keep the full dataset 
```{r}
library(randomForest)
set.seed(123)

# Variables for Forest
vars.forest <- c( "Week_Type", "mood_positive", "mood_negative", "sc_tonic_mean", "sc_phasic_mag", "sc_phasic_dur", "sc_phasic_auc", "sc_phasic_num","hr_mean", "hr_max", "hr_min", "hr_sd", "acc_delta", "temp_mean")
vars.forest.physio <-c( "sc_tonic_mean", "sc_phasic_mag", "sc_phasic_dur", "sc_phasic_auc", "sc_phasic_num","hr_mean", "hr_max", "hr_min", "hr_sd", "Week_Type" )

# Subset the data
df.RandomForest <- EMA_Data[,vars.forest]
df.RandomForest <- na.omit(df.RandomForest)
df.RandomForest.physio <- df.RandomForest[,vars.forest.physio]
```

## OOB Error {.tabset}

We first run the first analysis to establish the Out-Of-Bag (OOB) error rate without any cross validation. This is done to establish the models first, and fine tune the paramters (for example, the number of trees required for model stability and such). This is done with three models in mind:

Model 1. Mood
Model 2. Physiology
Model 3. Combination

Model 1 classifies week from the EMA mood outcomes, while Model 2 does the same using the EPA output. We then finally test these models using the combination thereof in Model 3. After we check these models, we can then go ahead and run the models with cross validation in the next sections.Based on the OOB, we see that the combined model does the best, while the physiology model does the worst. 

### Model 1: Mood {-}
This model classifies week type from the affect items
```{r}
# Run random forest model for mood vars
forest.mood <- randomForest(Week_Type ~ mood_positive + mood_negative,
                            data=df.RandomForest, 
                            ntree=5000,
                          importance = TRUE)
forest.mood
```

### Model 2: Physio {-}
Now we can check what the physio data looks like. 
```{r}
# Run random forest full model
vars.forest.physio <- c( "sc_tonic_mean", "sc_phasic_mag", "sc_phasic_dur", "sc_phasic_auc", "sc_phasic_num","hr_mean", "hr_max", "hr_min", "hr_sd", "acc_delta", "temp_mean")
forest.full <- randomForest( as.formula(paste("Week_Type", "~", (paste(vars.forest.physio, collapse="+")))) ,
                            data=df.RandomForest, 
                            ntree=5000,
                            importance = TRUE)
forest.full
randomForest::importance(forest.full)
```


### Model 3: Combined {-}
Next up we check the entire data set and see if using both is good. 
```{r}
# Run the forest with most important features
forest.important <- randomForest(Week_Type ~ .,
                            data=df.RandomForest, 
                            ntree=5000,
                            importance = TRUE)
forest.important
```


## LOBO

In order to perform the validation, we try out a leave-one-beep-out (LOBO) analysis. This analysis will run a random forest model for each subject separately, leaving out one survey when running the model. We then test the model on the beep that was left out. We repeat this process for the subject until we've removed each survey/beep out once. This results in a series of predictions that give us an error level for each subject. In order to do this, we have developed a function that is provided in this github directory mentioned in the introducton. This will produce the classification errors for each subject.

We also need to test all our models against the  true chance levels. One can assume in theory that the prediction error for a dichotomous variable is 50/50, but we dont like to do things the easy way. Instead, we will do 10000 iterations where we bootstrap resample the stress and control weeks. This will give us the real error rate with a sampling distribution. This was made into a function, but for some reason I couldnt get the function to run in parallel processing on our unix system. So instead I run the parallel processing of the bootstrap outside of a function. Its not pretty, but it works. 

We also test the LOBO model using against the bootstrapped LOBO model. We also made a function to do this. The function estimates the p-value by comparing it to the permuation test distribution. The function also has the option to estimate the p-value from an assumed normal distribution, but we simply use the actual distribution for this. We additionally compute a combined p-value with this function using Stouffer method and the poolr package. 

This results in the three tabs for each model:

1. **Model:** Contains the actual results of the LOBO model
2. **Bootstrap:** Contains the bootstrap error estimation results
3. **Stouffer's tests:** Contains the tests against the null distribution and the pooled p-values

### Model 1: Mood {.tabset}
Some parts of the code are commented to make producing the notebook easier, we see that the mean LOBO error rate is 33.45 percent, and that the model performs relatively well on most subjects. Based on the estimated bootstrap error distribution of around 50%, we also show that this model performs above chance. 

#### Model {-}
```{r}
# Then with the full model
vars.forest.mood <-  c("mood_positive_c", "mood_negative_c")
# forest.lobo.mood <- rf.lobo(Data=EMA_Data,
#                               SubNr="castor_record_id",
#                            xvars=vars.forest.mood,
#                               yvar="Week_Type",
#                               NoTree=5000)
as.data.frame(forest.lobo.mood$total$subject_errors)
psych::describe(forest.lobo.mood$total$subject_errors)

```



#### Bootstrap{-}
```{r warning=FALSE}
# BootstrapLOBO.
# { cl <- makeCluster(NoCores-1)
# registerDoSNOW(cl)
# iterations <- 10000
# print("Running, this will take a while...", quote=F)
# pb <- txtProgressBar(max = iterations, style = 3)
# progress <- function(n) setTxtProgressBar(pb, n)
# opts <- list(progress = progress)
# forest.boot.mood <- foreach(i=1:iterations, .options.snow = opts ) %dopar% {
#     rf.BootstrapError(Data=EMA_Data,
#                           Shuffle="Week_Type",
#                           Iterations=1,
#                           SubjectId="castor_record_id",
#                           xvar=vars.forest.mood,
#                           yvar="Week_Type",
#                           Trees=500)
# }
# print("Done!", quote=F)
# stopCluster(cl)
# # Now merge them into one dataframe
# pb <- txtProgressBar(max =length(forest.boot.mood), style = 3)
# forest.boot.mood.merge <- as.data.frame(forest.boot.mood[[1]][2])
# for (i in 2:length(forest.boot.mood)) {
#     setTxtProgressBar(pb, i)
#     df.2merge <- as.data.frame(forest.boot.mood[[i]][2])
#     forest.boot.mood.merge <- merge (df.2merge, forest.boot.mood.merge , by="DataFrame.id")
# }
# # After merging the results into a single data frame, lets also everage the error rate
# forest.boot.mood.merge$averageError <- rowMeans(forest.boot.mood.merge [, -which(names( forest.boot.mood.merge) %in% c("DataFrame.id"))], na.rm=T)
# saveRDS(forest.boot.mood.merge, file = "data/bootstrap_mood.rds")
# }
``` 


Now that we have run the bootstrap, we also save it just in case, and then we get the average error, and calcualte the true SD and SE from the sampling distribution. 
```{r}
# Print the Errors
boot.mood.descr <- psych::describe(forest.boot.mood.merge$averageError)
# Also get the true SD of bootstraps
boot.mood.descr$sd <- mean((psych::describe(forest.boot.mood.merge))$sd, na.rm=T)
boot.mood.descr$se <- mean((psych::describe(forest.boot.mood.merge))$se, na.rm=T)
boot.mood.descr

```

 
#### Stouffer's Test{-}

```{r}

lobo.mood_null <- rf.null_test(forest.lobo.mood, forest.boot.mood.merge, model_type="LOBO", method="actual")
lobo.mood_null
```



### Model 2: Physiology {.tabset}

The second model I will test is whether we can predict week type from the physiology data alone. For this model, the LOBO error rate is 36.11, which is still better than chance level predictions, but worse than model 1.

#### Model {-}

```{r}
# Then with the full model
# vars.forest.physio <-  c("sc_tonic_mean", "sc_phasic_mag", "sc_phasic_dur", "sc_phasic_auc", "sc_phasic_num","hr_mean", "hr_max", "hr_min", "hr_sd", "acc_delta", "temp_mean")
# forest.lobo.physio <- rf.lobo(Data=EMA_Data,
#                               SubNr="castor_record_id",
#                               xvars=vars.forest.physio,
#                               yvar="Week_Type",
#                               NoTree=5000)
as.data.frame(forest.lobo.physio$total$subject_errors)
psych::describe(forest.lobo.physio$total$subject_errors)

```

#### Bootstrap{-}
We again do the bootstrap model, and then save it as an object for later use. 
```{r}
# # LOBO Bootstrapping
# { cl <- makeCluster(NoCores-1)
#     registerDoSNOW(cl)
#     iterations <- 10000
#     print("Running, this will take a while...", quote=F)
#     pb <- txtProgressBar(max = iterations, style = 3)
#     progress <- function(n) setTxtProgressBar(pb, n)
#     opts <- list(progress = progress)
#     forest.boot.physio <- foreach(i=1:iterations, .options.snow = opts ) %dopar% {
#         rf.BootstrapError(Data=EMA_Data,
#                                           Shuffle="Week_Type",
#                                           Iterations=1,
#                                           SubjectId="castor_record_id",
#                                           xvar=vars.forest.physio,
#                                           yvar="Week_Type",
#                                           Trees=500)
#     }
#     print("Done!", quote=F)
#     stopCluster(cl)
#     
#     # Now merge them into one dataframe
#     pb <- txtProgressBar(max =length(forest.boot.physio), style = 3)
#     forest.boot.physio.merge <- as.data.frame(forest.boot.physio[[1]][2])
#     for (i in 2:length(forest.boot.physio)) {
#         setTxtProgressBar(pb, i)
#         df.2merge <- as.data.frame(forest.boot.physio[[i]][2])
#         forest.boot.physio.merge <- merge(df.2merge, forest.boot.physio.merge , by="DataFrame.id",
#                                           suffixes=c((paste(i,".x")),(paste(i,".y"))))
#     }
#     # Merge it to mean
#     forest.boot.physio.merge$averageError <- rowMeans(forest.boot.physio.merge [, -which(names( forest.boot.physio.merge) %in% c("DataFrame.id"))], na.rm=T)
#     saveRDS( forest.boot.physio.merge, file = "data/bootstrap_physio.rds")
# }
```

We now calculate the bootstrap SE and SD
```{r}
# Print the Errors
boot.physio.descr <- psych::describe(forest.boot.physio.merge$averageError)
# Also get the true SD of bootstraps
boot.physio.descr$sd <- mean((psych::describe(forest.boot.physio.merge))$sd, na.rm=T)
boot.physio.descr$se <- mean((psych::describe(forest.boot.physio.merge))$se, na.rm=T)
boot.physio.descr
```

#### Stouffer's Test{-}

So now that I have the averaged bootstrap error for the physio model, lets check if the LOBO is more than random with a test against the bootstrap estimates. 
```{r}
lobo.physio_null <- rf.null_test(forest.lobo.physio, forest.boot.physio.merge,  model_type="LOBO", method="actual")
lobo.physio_null
```

According to the t-test against the bootstrap error sample, the test is above chance level here too. I will again do a model comparison at the end of the model-testing sections.

### Model 3: Combined {.tabset}

Finally we check the full model using both physio and mood variables. This model perfroms better than the mood model. It also perfroms better than chance for each subject, with the pooled effect being significant. 

#### Model{-}
```{r}
# Then with the full model
# vars.forest.x <-  c("mood_positive_c", "mood_negative_c", "sc_tonic_mean", "sc_phasic_mag", "sc_phasic_dur", "sc_phasic_auc", "sc_phasic_num","hr_mean", "hr_max", "hr_min", "hr_sd", "temp_mean")
# forest.lobo.full <- rf.lobo(Data=EMA_Data,
#                               SubNr="castor_record_id",
#                               xvars=vars.forest.x,
#                               yvar="Week_Type",
#                               NoTree=5000)
as.data.frame(forest.lobo.full$total$subject_errors)
psych::describe(forest.lobo.full$total$subject_errors)

``` 


#### Bootstrap{-}
Then I can check the bootstrap error for the model combined model as done before:
```{r}
# {cl <- makeCluster(NoCores-1)
# registerDoSNOW(cl)
# iterations <- 10000
# print("Running, this will take a while...", quote=F)
# pb <- txtProgressBar(max = iterations, style = 3)
# progress <- function(n) setTxtProgressBar(pb, n)
# opts <- list(progress = progress)
# forest.boot.combi <- foreach(i=1:iterations, .options.snow = opts ) %dopar% {
#     rf.BootstrapError(Data=EMA_Data,
#                                       Shuffle="Week_Type",
#                                       Iterations=1,
#                                       SubjectId="castor_record_id",
#                                       xvar=vars.forest.x,
#                                       yvar="Week_Type",
#                                       Trees=500)
# }
# print("Done!", quote=F)
# stopCluster(cl)
# 
# # Now merge them into one dataframe
# pb <- txtProgressBar(max =length(forest.boot.combi), style = 3)
# forest.boot.combi.merge <- as.data.frame(forest.boot.physio[[1]][2])
# for (i in 2:length(forest.boot.combi)) {
#     setTxtProgressBar(pb, i)
#     df.2merge <- as.data.frame(forest.boot.combi[[i]][2])
#     forest.boot.combi.merge <- merge(df.2merge, forest.boot.combi.merge , by="DataFrame.id",
#                                       suffixes=c((paste(i,".x")),(paste(i,".y"))))
# }
# # Merge it to mean
# forest.boot.combi.merge$averageError <- rowMeans(forest.boot.combi.merge [, -which(names( forest.boot.combi.merge) %in% c("DataFrame.id"))], na.rm=T)
#  saveRDS( forest.boot.combi.merge, file = "data/bootstrap_combi.rds")
# }
```

We then again calculate the SE and SD of the models
```{r}
# Print the Errors
boot.combi.descr <- psych::describe(forest.boot.combi.merge$averageError)
# Also get the true SD of bootstraps
boot.combi.descr$sd <- mean((psych::describe(forest.boot.combi.merge))$sd, na.rm=T)
boot.combi.descr$se <- mean((psych::describe(forest.boot.combi.merge))$se, na.rm=T)
boot.combi.descr

```

#### Stouffer's Test{-}
And finally I can test the difference between the full model and the bootstrapped one. So we can see again, that our model only improves slightly with the addition of the physio variables (1%). That doesnt seem great. But we can also guess that within the control week there may be times when people are stressed, and vice versa for the stress week.We will do the null test again.

```{r}
lobo.combi_null <- rf.null_test(forest.lobo.full, forest.boot.combi.merge, model_type="LOBO", method="actual")
lobo.combi_null
```



### Whats the best LOBO? {.tabset}

We now test the LOBO models against each other. We start with the highest error rates, and that is the mood and physiology models (models 1 and 2). We then test the mood against the combined LOBO model, Based on these results, we see that Model 3 > Model 1 > Model 2. 

#### Mood vs Physio {-}
We filter the data and have to do a couple of manipulations to do a paired t-test.We see that the mood does significantly better
```{r}

rf.result.df1 <- as.data.frame(forest.lobo.physio$total$subject_errors)
colnames(rf.result.df1)[1] <- "physio"
rf.result.df1$id <- rownames(rf.result.df1)

rf.result.df2 <- as.data.frame(forest.lobo.mood$total$subject_errors)
colnames(rf.result.df2)[1] <- "mood"
rf.result.df2$id <- rownames(rf.result.df2)

rf.result.merge <- merge(rf.result.df1, rf.result.df2, by="id")
tidy(t.test(x=rf.result.merge$physio, y=rf.result.merge$mood, paired=T))
```


#### Combi vs Mood {-}
Now I test the mood vs full model. It appears that the full model does a lot better than the one with mood only. So it is safe to say that Model 3 > Model 1 > Model 2
```{r}

rf.result.df1 <- as.data.frame(forest.lobo.full$total$subject_errors)
colnames(rf.result.df1)[1] <- "full"
rf.result.df1$id <- rownames(rf.result.df1)

rf.result.df2 <- as.data.frame(forest.lobo.mood$total$subject_errors)
colnames(rf.result.df2)[1] <- "mood"
rf.result.df2$id <- rownames(rf.result.df2)

rf.result.merge <- merge(rf.result.df1, rf.result.df2, by="id")
tidy(t.test(x=rf.result.merge$full, y=rf.result.merge$mood, paired=T))
```




## LOSO

In order to determine whether the models can be generalized beyond the individial, we use a standard Leave-One-Subject-Out approach. In this analysis, we remove an entire subjects data set from the training set. We train our models on the remaining data, and then test the classification errors on the subject that was left out. This process is repeated until every subject has been removed once, thus providing error rates for each subject. For each model, we present the estimated LOSO error rates, and the test against the previously estimated null distribution. 

### Model 1: Mood {.tabset}

#### Model{-}
Our first model looks at the mood ratings predicting which week participants are in. I estimate the LOSO error rates below. The model here doesnt do as well as the model with the lobo. Lets try to use the LOBO null distribution to see if its above chance levels next.
```{r}
# First with mood items
# vars.forest.mood <-  c("mood_positive", "mood_negative")
# forest.loso.mood <- rf.loso(Data=EMA_Data, 
#                        SubNr="castor_record_id", 
#                        xvars=vars.forest.mood,
#                        yvar="Week_Type",
#                        NoTree=5000)
as.data.frame(forest.loso.mood$error_rate)
psych::describe(forest.loso.mood$error_rate*100, na.rm=T)

```

#### Test {-}
Here I will try to check the LOSO model vs. the null distribution estimated from the bootstrap we did earler. The loso model did not perform better than the bootstrapped estimates.
```{r}

forest.loso_mood_null <- rf.null_test(forest.loso.mood, forest.boot.mood.merge,  model_type="LOSO", method="actual")
forest.loso_mood_null

```


### Model 2: Physiology {.tabset}

The second model is looking at the physio variables predicting week type. We see that it only achieves 47.83% success. We will test this now against the bootstrapped error rate.
#### Model{-}
```{r}
# Then with the full model
# vars.forest.physio <-  c("sc_tonic_mean", "sc_phasic_mag", "sc_phasic_dur", "sc_phasic_auc", "sc_phasic_num","hr_mean", "hr_max", "hr_min", "hr_sd", "acc_delta", "temp_mean")
# forest.loso.physio <- rf.loso(Data=EMA_Data, 
#                        SubNr="castor_record_id", 
#                        xvars=vars.forest.physio,
#                        yvar="Week_Type",
#                        NoTree=5000)
as.data.frame(forest.loso.physio$error_rate)
psych::describe(forest.loso.physio$error_rate*100)
``` 

#### Test{-}
Next we check the physio variables against the null distribution. Here we see that it its also not signficantly better than chance.
```{r}
forest.loso_physio_null <- rf.null_test(forest.loso.physio, forest.boot.physio.merge, model_type="LOSO", method="actual")
forest.loso_physio_null
```

### Model 3: Combined {.tabset}
FInally, the third model looks at everything (i.e. both physio and mood). This has an error rate of 43% which still sucks. Lets test this next against the bootstrap error

#### Model {-}
```{r}
# Then with the full model
# vars.forest.x <-  c("mood_positive_c", "mood_negative_c",  "sc_tonic_mean", "sc_phasic_mag", "sc_phasic_dur", "sc_phasic_auc", "sc_phasic_num","hr_mean", "hr_max", "hr_min", "hr_sd", "acc_delta", "temp_mean")
# forest.loso.full <- rf.loso(Data=EMA_Data, 
#                        SubNr="castor_record_id", 
#                        xvars=vars.forest.x,
#                        yvar="Week_Type",
#                        NoTree=5000)
as.data.frame(forest.loso.full$error_rate)
psych::describe(forest.loso.full$error_rate*100)

``` 
#### Test {-}
Finally we test the model with both against the null distribution.This one is also not significantly better than chance.  
```{r}
forest.loso_full_null <- rf.null_test(forest.loso.full, forest.boot.combi.merge, model_type="LOSO", method="actual")
forest.loso_full_null

```

Based on all three tests for the models against the null we can conclude that the LOSO models do not in fact perform better than chance. 

### Whats the best LOSO? {-}

Based on the error rate, lets see if one model does a better job than the other:
```{r}
rf.loso.mood <- as.data.frame(forest.loso.mood$error_rate)
rf.loso.mood$id <- rownames(rf.loso.mood)

rf.loso.physio <- as.data.frame(forest.loso.physio$error_rate)
rf.loso.physio$id <- rownames(rf.loso.physio)

rf.loso.full <- as.data.frame(forest.loso.full$error_rate)
rf.loso.full$id <- rownames(rf.loso.full)

rf.result.merge <- merge(rf.loso.mood, rf.loso.physio, by="id")
rf.result.merge <- merge(rf.result.merge, rf.loso.full, by="id")
```


```{r}
tidy(t.test(x=rf.result.merge$`forest.loso.mood$error_rate`, y=rf.result.merge$`forest.loso.physio$error_rate`, paired=T))
tidy(t.test(x=rf.result.merge$`forest.loso.mood$error_rate`, y=rf.result.merge$`forest.loso.full$error_rate`, paired=T))
tidy(t.test(x=rf.result.merge$`forest.loso.physio$error_rate`, y=rf.result.merge$`forest.loso.full$error_rate`, paired=T))
```

It looks like there is no significant difference between the error rates in the paired sample t-test in these three models. What could this mean? That regardless of what model we use at a population level, we still are not able to make decent predictions. I think that these models arent good at population level predictions, and this is pretty obnvious if we look at the within-subject variance from our linear models. Most of the variance comes from between subjects. Another approach is warranted.


## Plot of Models

We next waht to make a plot of my models with the standard error. We first merge them into one dataframe, then we can actually plot them. 
```{r}

# I will rename the bootstrap coloumns so I can add them to the full model dataframe for plotting
df_boot1 <- forest.boot.mood.merge[,c("DataFrame.id" ,"averageError")]
df_boot1 <- df_boot1 %>% dplyr::rename(id=DataFrame.id, error=averageError) 
df_boot1 <- tibble::add_column(df_boot1, model="boot.mood", .after="id")
df_boot2 <- forest.boot.physio.merge %>% dplyr::select(DataFrame.id, averageError) %>% dplyr::rename(id=DataFrame.id, error=averageError) 
df_boot2 <- tibble::add_column(df_boot2, model="boot.physio", .after="id")
df_boot3 <- forest.boot.combi.merge %>% dplyr::select(DataFrame.id, averageError) %>% dplyr::rename(id=DataFrame.id, error=averageError) 
df_boot3 <- tibble::add_column(df_boot3, model="boot.full", .after="id")
# Join the boot straps
df_boot <- full_join(df_boot1, df_boot2) 
df_boot <- full_join(df_boot, df_boot3)
# Make the results and merge boot
df_loo <- gather(rf.combined.errors,model, error, loso.mood:lobo.full, factor_key=TRUE)
df_loo <- full_join(df_loo, df_boot)
# Separate coloumns for plotting
df_loo <- separate(df_loo, model, into=c("Method", "Model"))



df_loo_sum <- data_summary(df_loo, "error", c("Method", "Model"))
# Set the SD and SE of bootstrap models to the correct ones of whole model
df_loo_sum$sd[df_loo_sum$Method=="boot" & df_loo_sum$Model=="mood"] <- boot.mood.descr$sd
df_loo_sum$se[df_loo_sum$Method=="boot" & df_loo_sum$Model=="mood"] <- boot.mood.descr$se
df_loo_sum$sd[df_loo_sum$Method=="boot" & df_loo_sum$Model=="physio"] <- boot.physio.descr$sd
df_loo_sum$se[df_loo_sum$Method=="boot" & df_loo_sum$Model=="physio"] <- boot.physio.descr$se
df_loo_sum$sd[df_loo_sum$Method=="boot" & df_loo_sum$Model=="full"] <- boot.combi.descr$sd
df_loo_sum$se[df_loo_sum$Method=="boot" & df_loo_sum$Model=="full"] <- boot.combi.descr$se

# Set the factor to make it pretty
df_loo_sum$Method <- factor(df_loo_sum$Method, levels =c("lobo", "loso", "boot"), labels = c("LOBO", "LOSO", "Bootstrap"))
df_loo_sum$Model<- factor(df_loo_sum$Model, levels =c("mood", "physio", "full"), labels = c("Model 1:\nMood", "Model 2:\n Physiology", "Model 3:\nCombination"))

figure.loo <- ggplot(df_loo_sum, aes(x=Model, y=error, colour=Method, fill=Method)) +
    geom_bar(stat="summary", position = position_dodge2()) + 
    geom_errorbar(aes(ymin=error-se, ymax=error+se), width=.2, position=position_dodge(.9), colour="black")  + 
    scale_y_continuous(breaks=c(0,10,20,30,40,50, 60, 70, 80), minor_breaks=c(5,15,25,35,45,55,65,75, 85) )+ 
    scale_colour_brewer(palette="Set2") + scale_fill_brewer(palette="Set2") + 
    xlab("")+ ylab("Error Rate (%)\n") + 
    theme(text=element_text(size=16,  family="Calibri"), 
          axis.line = element_line(size = 1, colour = "grey"),
          panel.background = element_rect(fill="transparent"),
        panel.grid.minor.y = element_line(colour="grey95"),
        panel.grid.major.y = element_line(colour = "grey95")); 
ggsave("figures/fig_RFModels.tiff", units="in", width=4, height=4, dpi=300, compression = 'lzw')
figure.loo
```

## Testing All Models

Now we want to see for each of the models, which one performs best. I first need to split the long dataframe I made for the figures into a wide format.
```{r}
df_loo_wide <- pivot_wider(df_loo,id_cols = id, names_from=c(Method, Model), values_from=error)
print(df_loo_wide)
#write_csv(df_loo_wide, file = "data/LOO_DF.csv")
```


### Model 1: Mood {.tabset}

#### LOBO vs Boot {-}
```{r}
tidy(t.test(df_loo_wide$lobo_mood, df_loo_wide$boot_mood , paired = T))

```

#### LOSO vs Boot {-}

```{r}
tidy(t.test(df_loo_wide$loso_mood, df_loo_wide$boot_mood , paired = T))

```

#### LOBO  vs LOSO {-}
```{r}

tidy(t.test(df_loo_wide$lobo_mood, df_loo_wide$loso_mood , paired = T))
```


### Model 2: Physio {.tabset}

#### LOBO vs Boot {-}
```{r}

tidy(t.test(df_loo_wide$lobo_physio, df_loo_wide$boot_physio , paired = T))

```

#### LOSO vs Boot {-}

```{r}

tidy(t.test(df_loo_wide$loso_physio, df_loo_wide$boot_physio , paired = T))

```


#### LOBO  vs LOSO {-}
```{r}

tidy(t.test(df_loo_wide$lobo_physio, df_loo_wide$loso_physio , paired = T))

```



### Model 3: Full Model {.tabset}

#### LOBO vs Boot {-}
```{r}

tidy(t.test(df_loo_wide$lobo_full, df_loo_wide$boot_full , paired = T))

```

#### LOSO vs Boot {-}

```{r}

tidy(t.test(df_loo_wide$loso_full, df_loo_wide$boot_full , paired = T))

```


#### LOBO  vs LOSO {-}
```{r}

tidy(t.test(df_loo_wide$lobo_full, df_loo_wide$loso_full , paired = T))

```

# System Info
```{r}
sessionInfo()
```



